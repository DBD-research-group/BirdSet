{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This file is used to generate the metadata files for diverse datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Before running this notebook make shure that the data is in folders corresponding to the dataset names. The folder structure of the datafolder should be as follows:\n",
    "- data_path\n",
    "    - Data\n",
    "        - OekoFor\n",
    "            - 2016_Scotland\n",
    "                - *audio_files*\n",
    "            - ...\n",
    "        - Zenodo\n",
    "            - *audio_files*\n",
    "        - Powdermill\n",
    "            - Recording_1\n",
    "                - *audio_files*\n",
    "            - ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The path to the folder containing all audiofiles, this folder should be named Data\n",
    "#If Data is in the same directory as this notebook the data_path should be the empty string\n",
    "data_path = \"/data-project/DeepBirdDetect/BirdSet/\"\n",
    "#The path to where annotation files are stored\n",
    "annotations_path = \"Annotations/\"\n",
    "#The path to where the gernerated metadata should be stored\n",
    "metadata_path = \"Metadata/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 79 out of 2326 entrys in the Alpha codes which I could not translate to ebirdcodes\n",
      "There are 4 out of 2251 entrys in the NIPS4BPlus codes which I could not translate to ebirdcodes\n",
      "Subalpine Warbler/ Sylvia cantillans\n",
      "Subalpine Warbler/ Sylvia cantillans\n",
      "Mediterranean Warbler/ Sylvia melanocephala\n",
      "Mediterranean Warbler/ Sylvia melanocephala\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build an empty dictionary with the colmun-names as keys. For each dataset (i.e. Oeko4, Powdermill, etc.) the empty_dataset is deepcopied and filled.\n",
    "The resulting dataset can then be converted into a HuggingFace Dataset object.\n",
    "Also build dictionarys to translate different bird-codes\n",
    "\"\"\"\n",
    "\n",
    "columns=[\"id\", \"filepath\", \"start_time\", \"end_time\", \"low_freq\", \"high_freq\", \"ebird_code\"\n",
    "         , \"call_type\", \"sex\", \"lat\", \"long\", \"microphone\", \"license\", \"source\", \"local_time\"]\n",
    "\"\"\"\n",
    "Read the taxonomy from the csv file and convert it to the e_bird_codes dictionary.\n",
    "common_to_ebird maps common_names to e-bird-codes\n",
    "\"\"\"\n",
    "import csv\n",
    "common_to_ebird = {} #This dict saves the e-bird-code for each common name\n",
    "with open('ebird_taxonomy_v2022.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        common_name = row[3]\n",
    "        e_bird_code = row[2]\n",
    "        common_to_ebird[common_name]=e_bird_code\n",
    "\n",
    "\"\"\"\n",
    "The sci_to_ebird dictionary maps each scientific (latin) name to the corresponding e-bird-code.\n",
    "\"\"\"\n",
    "import csv\n",
    "sci_to_ebird = {} #This dict saves the e-bird-code for each common name\n",
    "with open('ebird_taxonomy_v2022.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        sci_name = row[4]\n",
    "        e_bird_code = row[2]\n",
    "        sci_to_ebird[sci_name]=e_bird_code\n",
    "\n",
    "\"\"\"\n",
    "The ebird_to_common dictionary maps each e-bird-code to the corresponding common name.\n",
    "\"\"\"\n",
    "ebird_to_common = {} #This dict saves the e-bird-code for each common name\n",
    "with open('ebird_taxonomy_v2022.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        common_name = row[3]\n",
    "        e_bird_code = row[2]\n",
    "        ebird_to_common[e_bird_code]=common_name\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The alpha_to_ebird dictionary maps each alpha-code to the corresponding ebird-code.\n",
    "\"\"\"\n",
    "alpha_to_ebird = {} #This dict saves the alpha-code for each e_bird_code\n",
    "not_found = []\n",
    "non_bird_sound = []\n",
    "with open('AlphaCodes.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        common_name = row[3]\n",
    "        alpha_code = row[1]\n",
    "        sci_name = row[4]\n",
    "        if sci_name in sci_to_ebird.keys():\n",
    "            alpha_to_ebird[alpha_code]=sci_to_ebird[sci_name]\n",
    "        elif common_name in common_to_ebird.keys():\n",
    "            #If the scientific name can not be found try the common name\n",
    "            alpha_to_ebird[alpha_code]=common_to_ebird[common_name]\n",
    "        else:\n",
    "            not_found.append(f\"{common_name}/ {sci_name}\")\n",
    "print(f\"There are {len(not_found)} out of {len(not_found)+len(alpha_to_ebird.keys())} entrys in the Alpha codes which I could not translate to ebirdcodes\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The NIPS4BPlus dataset uses it's verry own bird names. The nips_to_ebird dictionary maps these bird names to the corresponding ebird-codes.\n",
    "\"\"\"\n",
    "nips_to_ebird = {} #This dict saves the nips4bplus names for each e_bird_code\n",
    "not_found = []\n",
    "with open('nips4b_birdchallenge_espece_list.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "\n",
    "        common_name = row[2]\n",
    "        nips_code = row[1]\n",
    "        sci_name = row[3]\n",
    "        type = row[4]\n",
    "\n",
    "        #fixing a misspelled name\n",
    "        if sci_name == \"lullula arborea\":\n",
    "            sci_name = \"Lullula arborea\"\n",
    "\n",
    "        if type != \"bird\":\n",
    "            #This is not a bird sound\n",
    "            pass\n",
    "        elif sci_name in sci_to_ebird.keys():\n",
    "            nips_to_ebird[nips_code]=sci_to_ebird[sci_name]\n",
    "        elif common_name in common_to_ebird.keys():\n",
    "            #If the scientific name can not be found try the common name\n",
    "            nips_to_ebird[nips_code]=common_to_ebird[common_name]    \n",
    "        else:\n",
    "            not_found.append(f\"{common_name}/ {sci_name}\")\n",
    "print(f\"There are {len(not_found)} out of {len(not_found)+len(alpha_to_ebird.keys())} entrys in the NIPS4BPlus codes which I could not translate to ebirdcodes\")\n",
    "for x in not_found:\n",
    "    print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zenodo\n",
    "The following Blocks build the Zenodo dataset and adds it to the list of datasets. The Zenodo dataset consists of 5 Datasets, namely HSN, SNE, UHH, PER, SSW and NES. These are stored as individual metadata-files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Constants\n",
    "The following codeblock defines some required constants. These include the folder names for the 5 Datasets, their respective sources, as well as their respective cooridinates (Latitude, Longitude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [\"HSN\", \"SNE\", \"UHH\", \"PER\", \"SSW\", \"NES\"]\n",
    "\n",
    "sources={\"HSN\": \"https://zenodo.org/record/7525805\",\n",
    "        \"SNE\": \"https://zenodo.org/record/7050014\",\n",
    "        \"UHH\": \"https://zenodo.org/record/7078499\",\n",
    "        \"PER\": \"https://zenodo.org/record/7079124\",\n",
    "        \"SSW\": \"https://zenodo.org/record/7079380\",\n",
    "        \"NES\": \"https://zenodo.org/record/7525349\"}\n",
    "\"\"\"\n",
    "Coordinates are saved as [latitude, logitude]. Some of the datasets contain multiple recording sights.\n",
    "I filled these in by hand, as the different datasets had used different formats which had to be \n",
    "converted to (Lat,Lon).\n",
    "\"\"\"\n",
    "coordinates={\"HSN\": {0:[37.0, -118.5]},\n",
    "             \"SNE\": {0:[38.49, -119.95]},\n",
    "             \"UHH\": {1:[19.801668, -155.609444],\n",
    "                     2:[19.792975, -155.321332],\n",
    "                     3:[19.46647, -155.582011],\n",
    "                     4:[19.820609, -155.468097]},\n",
    "             \"PER\": {1:[-12.542578, -69.062050],\n",
    "                     2:[-12.541925, -69.058642],\n",
    "                     4:[-12.537814, -69.054308],\n",
    "                     5:[-12.535539, -69.06674],\n",
    "                     6:[-12.532981, -69.049864],\n",
    "                     8:[-12.529858, -69.046164],\n",
    "                     10:[-12.522983, -69.046822]},\n",
    "             \"SSW\": {0:[42.4768, -76.4527]},\n",
    "             \"NES\": {1:[5.59,-75.85],\n",
    "                     2:[10.11,-84.52]}\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Dataset\n",
    "The following block builds a dictionary from the data and converts it into a HuggingFace Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from datetime import date, datetime, time, timedelta\n",
    "\n",
    "for subset in subsets:\n",
    "    ID=0\n",
    "    with open(f'{annotations_path}Zenodo/{subset}_annotations.csv', newline='') as annotations:\n",
    "        reader = csv.DictReader(annotations) \n",
    "        with open(f\"{metadata_path}{subset}_metadata.csv\",\"w\",newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(columns)\n",
    "            for sample in reader:\n",
    "                #filter out unknown birds (in the case of zenodo these are all marked as ????)\n",
    "                if sample[\"Species eBird Code\"] == \"????\":\n",
    "                    continue\n",
    "\n",
    "                # Some of the subsets used multiple recording sights\n",
    "                if subset in [\"UHH\",\"PER\",\"NES\"]:\n",
    "                    #This part of the filename denotes the Recording Sight\n",
    "                    sight = int(sample['Filename'][9:11])\n",
    "                else:\n",
    "                    sight = 0\n",
    "\n",
    "                #start time of the recording\n",
    "                #note that the date is irrelevant\n",
    "                if subset in [\"HSN\",\"SNE\",\"SSW\"]:\n",
    "                    t = sample['Filename'][17:23]\n",
    "                else:\n",
    "                    t = sample['Filename'][21:27]\n",
    "                start_time = time(int(t[0:2]),int(t[2:4]),int(t[4:6]))\n",
    "                local_time = datetime.combine(date.today(),start_time)\n",
    "                #the start of the actual bird sound is relative to the audiofile\n",
    "                local_time+=timedelta(seconds=int(float(sample['Start Time (s)'])))\n",
    "                row = []\n",
    "                row.append(str(ID))#id\n",
    "                row.append(f\"Data/Zenodo/{sample['Filename']}\")#filepath\n",
    "                row.append(sample[\"Start Time (s)\"])#start_time\n",
    "                row.append(sample[\"End Time (s)\"])#end_time\n",
    "                row.append(sample[\"Low Freq (Hz)\"])#low_freq\n",
    "                row.append(sample[\"High Freq (Hz)\"])#high_freq\n",
    "                row.append(sample[\"Species eBird Code\"])#ebird_code\n",
    "                row.append(None)#call_type\n",
    "                row.append(None)#sex\n",
    "                row.append(coordinates[subset][sight][0])#lat\n",
    "                row.append(coordinates[subset][sight][1])#long\n",
    "                row.append(\"Soundscape\")#microphone\n",
    "                row.append(\"Creative Commons Attribution 4.0 International Public License\")#license\n",
    "                row.append(sources[subset])#source\n",
    "                row.append(local_time)#local_time\n",
    "                writer.writerow(row)\n",
    "                ID += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Powdermill\n",
    "The powdermill dataset is also a **Zenodo** dataset, but it must be processed differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was unable to lable 62 samples\n",
      "Could not translate the following alpha-codes to ebird: ['AMGO']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import date, datetime, time, timedelta\n",
    "\n",
    "start_times = {\"Recording_1\":time(5,32), \"Recording_2\":time(5,32), \n",
    "               \"Recording_3\":time(5,17), \"Recording_4\":time(6,19)}\n",
    "folders = [\"Recording_1\", \"Recording_2\", \"Recording_3\", \"Recording_4\"]\n",
    "\n",
    "ID=0\n",
    "other_sounds=[]\n",
    "with open(f\"{metadata_path}POW_metadata.csv\",\"w\",newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(columns)\n",
    "    for folder in folders:\n",
    "        path = f\"{annotations_path}Powdermill/{folder}/\"\n",
    "        annotations = [name for name in os.listdir(path)]\n",
    "        for annotation_file in annotations:\n",
    "            with open(f'{path}{annotation_file}', newline='') as annotations:\n",
    "                reader = csv.DictReader(annotations, delimiter='\\t') \n",
    "                for sample in reader:                         \n",
    "                    #Samples that are not Birds are removed\n",
    "                    bird = sample[\"Species\"]\n",
    "                    if bird in alpha_to_ebird:\n",
    "                        bird = alpha_to_ebird[bird]\n",
    "                    else:\n",
    "                        other_sounds.append(bird)\n",
    "                        continue\n",
    "                    \n",
    "                    #For uniformity replace NA and \"\" with None\n",
    "                    for key in sample.keys():\n",
    "                        if sample[key] == \"NA\" or sample[key]==\"\":\n",
    "                            sample[key] = None\n",
    "                    \n",
    "                    #start time of the recording\n",
    "                    #note that the date is irrelevant\n",
    "                    local_time = datetime.combine(date.today(),start_times[folder])\n",
    "                    #each recording is split into segments in 5 minute intervals\n",
    "                    segment = int(annotation_file[20:22])\n",
    "                    local_time+=timedelta(minutes=segment*5)\n",
    "                    #the start of the actual bird sound is relative to the audiofile\n",
    "                    local_time+=timedelta(seconds=int(float(sample['Begin Time (s)'])))\n",
    "\n",
    "                    row = []\n",
    "                    row.append(str(ID))#id\n",
    "                    audio_name = f\"{folder}_Segment_{annotation_file[20:22]}.WAV\"\n",
    "                    row.append(f\"Data/Powdermill/{audio_name}\")#filepath\n",
    "                    row.append(sample['Begin Time (s)'])#start_time\n",
    "                    row.append(sample['End Time (s)'])#end_time\n",
    "                    row.append(sample['Low Freq (Hz)'])#low_freq\n",
    "                    row.append(sample['High Freq (Hz)'])#high_freq\n",
    "                    row.append(bird)#ebird_code\n",
    "                    row.append(None)#call_type\n",
    "                    row.append(None)#sex\n",
    "                    row.append(40.1602)#lat\n",
    "                    row.append(-79.2719)#long\n",
    "                    row.append(\"Soundscape (AudioMoths)\")#microphone\n",
    "                    row.append(\"Creative Commons Zero v1.0 Universal\")#license\n",
    "                    row.append(\"https://zenodo.org/record/4656848\")#source\n",
    "                    row.append(str(local_time.time()))#local_time\n",
    "                    writer.writerow(row)\n",
    "                    ID += 1\n",
    "print(f\"Was unable to lable {len(other_sounds)} samples\")\n",
    "print(f\"Could not translate the following alpha-codes to ebird: {list(dict.fromkeys(other_sounds))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIPS4BPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4453 columns created\n",
      "1322 labels not translatable\n"
     ]
    }
   ],
   "source": [
    "import csv, os\n",
    "from datetime import date, datetime, time, timedelta\n",
    "annotation_files = [name for name in os.listdir(f\"{annotations_path}NIPS4BPlus/\")]\n",
    "\n",
    "ID=0\n",
    "not_found = 0\n",
    "with open(f\"{metadata_path}NIPS4BPlus_metadata.csv\",\"w\",newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(columns)\n",
    "    for annotation_file in annotation_files:\n",
    "        with open(f'{annotations_path}NIPS4BPlus/{annotation_file}', newline='') as annotation_f:\n",
    "            reader = csv.DictReader(annotation_f, fieldnames = [\"start_time\",\"end_time\",\"label\"]) \n",
    "            for sample in reader:\n",
    "\n",
    "                bird = sample[\"label\"]\n",
    "                if bird not in nips_to_ebird.keys():\n",
    "                    not_found+=1\n",
    "                    continue\n",
    "\n",
    "\n",
    "                row = []\n",
    "                row.append(str(ID))#id\n",
    "                #row.append(f\"Data/Zenodo/{sample['Filename']}\")#filepath\n",
    "                row.append(sample[\"start_time\"])#start_time\n",
    "                row.append(sample[\"end_time\"])#end_time\n",
    "                #row.append(sample[\"Low Freq (Hz)\"])#low_freq\n",
    "                #row.append(sample[\"High Freq (Hz)\"])#high_freq\n",
    "                row.append(nips_to_ebird[sample[\"label\"]])#ebird_code\n",
    "                row.append(None)#call_type\n",
    "                row.append(None)#sex\n",
    "                #row.append(coordinates[subset][sight][0])#lat\n",
    "                #row.append(coordinates[subset][sight][1])#long\n",
    "                #row.append(\"Soundscape\")#microphone\n",
    "                #row.append(\"Creative Commons Attribution 4.0 International Public License\")#license\n",
    "                row.append(\"https://figshare.com/articles/dataset/Transcriptions_of_NIPS4B_2013_Bird_Challenge_Training_Dataset/6798548\")#source\n",
    "                #row.append(local_time)#local_time\n",
    "                writer.writerow(row)\n",
    "                ID += 1\n",
    "print(f\"{ID} columns created\")\n",
    "print(f\"{not_found} labels not translatable\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OekoFor\n",
    "The oekofor dataset still has some dificulties:\n",
    "- time can be extracted from the filenames (in Greenwich Mean Time)\n",
    "- the rough locantion can be extracted from the folder names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
