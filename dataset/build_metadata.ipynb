{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This file is used to generate the metadata files for diverse datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Before running this notebook make shure that the data is in folders corresponding to the dataset names. The folder structure of the datafolder should be as follows:\n",
    "- data_path\n",
    "    - Data\n",
    "        - OekoFor\n",
    "            - 2016_Scotland\n",
    "                - *audio_files*\n",
    "            - ...\n",
    "        - Zenodo\n",
    "            - *audio_files*\n",
    "        - Powdermill\n",
    "            - Recording_1\n",
    "                - *audio_files*\n",
    "            - ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The path to the folder containing all audiofiles, this folder should be named Data\n",
    "#If Data is in the same directory as this notebook the data_path should be the empty string\n",
    "data_path = \"/data-project/DeepBirdDetect/BirdSet/\"\n",
    "#The path to where annotation files are stored\n",
    "annotations_path = \"Annotations/\"\n",
    "#The path to where the gernerated metadata should be stored\n",
    "metadata_path = \"Metadata/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 79 out of 2326 entrys in the Alpha codes which I could not translate to ebirdcodes\n",
      "There are 0 out of 2247 entrys in the NIPS4BPlus codes which I could not translate to ebirdcodes\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build an empty dictionary with the colmun-names as keys. For each dataset (i.e. Oeko4, Powdermill, etc.) the empty_dataset is deepcopied and filled.\n",
    "The resulting dataset can then be converted into a HuggingFace Dataset object.\n",
    "Also build dictionarys to translate different bird-codes\n",
    "\"\"\"\n",
    "\n",
    "columns=[\"id\", \"filepath\", \"start_time\", \"end_time\", \"low_freq\", \"high_freq\", \"ebird_code\"\n",
    "         , \"call_type\", \"sex\", \"lat\", \"long\", \"microphone\", \"license\", \"source\", \"local_time\"]\n",
    "\"\"\"\n",
    "Read the taxonomy from the csv file and convert it to the e_bird_codes dictionary.\n",
    "common_to_ebird maps common_names to e-bird-codes\n",
    "\"\"\"\n",
    "import csv\n",
    "common_to_ebird = {} #This dict saves the e-bird-code for each common name\n",
    "with open('ebird_taxonomy_v2022.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        common_name = row[3]\n",
    "        e_bird_code = row[2]\n",
    "        common_to_ebird[common_name]=e_bird_code\n",
    "\n",
    "\"\"\"\n",
    "The sci_to_ebird dictionary maps each scientific (latin) name to the corresponding e-bird-code.\n",
    "\"\"\"\n",
    "import csv\n",
    "sci_to_ebird = {} #This dict saves the e-bird-code for each common name\n",
    "with open('ebird_taxonomy_v2022.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        sci_name = row[4]\n",
    "        e_bird_code = row[2]\n",
    "        sci_to_ebird[sci_name]=e_bird_code\n",
    "\n",
    "\"\"\"\n",
    "The ebird_to_common dictionary maps each e-bird-code to the corresponding common name.\n",
    "\"\"\"\n",
    "ebird_to_common = {} #This dict saves the e-bird-code for each common name\n",
    "with open('ebird_taxonomy_v2022.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        common_name = row[3]\n",
    "        e_bird_code = row[2]\n",
    "        ebird_to_common[e_bird_code]=common_name\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The alpha_to_ebird dictionary maps each alpha-code to the corresponding ebird-code.\n",
    "\"\"\"\n",
    "alpha_to_ebird = {} #This dict saves the alpha-code for each e_bird_code\n",
    "not_found = []\n",
    "non_bird_sound = []\n",
    "with open('AlphaCodes.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        common_name = row[3]\n",
    "        alpha_code = row[1]\n",
    "        sci_name = row[4]\n",
    "\n",
    "        #I am pretty shure that AMGP is a typo in the AlphaCodes.csv\n",
    "        #AMGO does not appear as a label for any sample\n",
    "        #AMGO does appear as a label for 62 samples but is not in AlphaCodes.csv\n",
    "        if alpha_code == \"AMGP\":\n",
    "            alpha_code = \"AMGO\"\n",
    "\n",
    "        if sci_name in sci_to_ebird.keys():\n",
    "            alpha_to_ebird[alpha_code]=sci_to_ebird[sci_name]\n",
    "        elif common_name in common_to_ebird.keys():\n",
    "            #If the scientific name can not be found try the common name\n",
    "            alpha_to_ebird[alpha_code]=common_to_ebird[common_name]\n",
    "        else:\n",
    "            not_found.append(f\"{common_name}/ {sci_name}\")\n",
    "print(f\"There are {len(not_found)} out of {len(not_found)+len(alpha_to_ebird.keys())} entrys in the Alpha codes which I could not translate to ebirdcodes\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The NIPS4BPlus dataset uses it's verry own bird names. The nips_to_ebird dictionary maps these bird names to the corresponding ebird-codes.\n",
    "\"\"\"\n",
    "nips_to_ebird = {} #This dict saves the nips4bplus names for each e_bird_code\n",
    "nips_to_ebird[\"Human\"]=\"not_a_bird\"\n",
    "not_found = []\n",
    "with open('nips4b_birdchallenge_espece_list.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "\n",
    "        common_name = row[2]\n",
    "        nips_code = row[1]\n",
    "        sci_name = row[3]\n",
    "        type = row[4]\n",
    "\n",
    "        #fixing a misspelled name\n",
    "        if sci_name == \"lullula arborea\":\n",
    "            sci_name = \"Lullula arborea\"\n",
    "        \n",
    "        #fixing synonimous scientific names\n",
    "        if sci_name == \"Sylvia cantillans\":\n",
    "            sci_name = \"Curruca cantillans\"\n",
    "        if sci_name == \"Sylvia melanocephala\":\n",
    "            sci_name = \"Curruca melanocephala\"\n",
    "\n",
    "        if type != \"bird\":\n",
    "            #This is not a bird sound\n",
    "            nips_to_ebird[nips_code]=\"not_a_bird\"\n",
    "        elif sci_name in sci_to_ebird.keys():\n",
    "            nips_to_ebird[nips_code]=sci_to_ebird[sci_name]\n",
    "        elif common_name in common_to_ebird.keys():\n",
    "            #If the scientific name can not be found try the common name\n",
    "            nips_to_ebird[nips_code]=common_to_ebird[common_name]    \n",
    "        else:\n",
    "            not_found.append(f\"{common_name}/ {sci_name}\")\n",
    "print(f\"There are {len(not_found)} out of {len(not_found)+len(alpha_to_ebird.keys())} entrys in the NIPS4BPlus codes which I could not translate to ebirdcodes\")\n",
    "for x in not_found:\n",
    "    print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zenodo\n",
    "The following Blocks build the Zenodo dataset and adds it to the list of datasets. The Zenodo dataset consists of 5 Datasets, namely HSN, SNE, UHH, PER, SSW and NES. These are stored as individual metadata-files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Constants\n",
    "The following codeblock defines some required constants. These include the folder names for the 5 Datasets, their respective sources, as well as their respective cooridinates (Latitude, Longitude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [\"HSN\", \"SNE\", \"UHH\", \"PER\", \"SSW\", \"NES\"]\n",
    "\n",
    "sources={\"HSN\": \"https://zenodo.org/record/7525805\",\n",
    "        \"SNE\": \"https://zenodo.org/record/7050014\",\n",
    "        \"UHH\": \"https://zenodo.org/record/7078499\",\n",
    "        \"PER\": \"https://zenodo.org/record/7079124\",\n",
    "        \"SSW\": \"https://zenodo.org/record/7079380\",\n",
    "        \"NES\": \"https://zenodo.org/record/7525349\"}\n",
    "\"\"\"\n",
    "Coordinates are saved as [latitude, logitude]. Some of the datasets contain multiple recording sights.\n",
    "I filled these in by hand, as the different datasets had used different formats which had to be \n",
    "converted to (Lat,Lon).\n",
    "\"\"\"\n",
    "coordinates={\"HSN\": {0:[37.0, -118.5]},\n",
    "             \"SNE\": {0:[38.49, -119.95]},\n",
    "             \"UHH\": {1:[19.801668, -155.609444],\n",
    "                     2:[19.792975, -155.321332],\n",
    "                     3:[19.46647, -155.582011],\n",
    "                     4:[19.820609, -155.468097]},\n",
    "             \"PER\": {1:[-12.542578, -69.062050],\n",
    "                     2:[-12.541925, -69.058642],\n",
    "                     4:[-12.537814, -69.054308],\n",
    "                     5:[-12.535539, -69.06674],\n",
    "                     6:[-12.532981, -69.049864],\n",
    "                     8:[-12.529858, -69.046164],\n",
    "                     10:[-12.522983, -69.046822]},\n",
    "             \"SSW\": {0:[42.4768, -76.4527]},\n",
    "             \"NES\": {1:[5.59,-75.85],\n",
    "                     2:[10.11,-84.52]}\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Dataset\n",
    "The following block builds a dictionary from the data and converts it into a HuggingFace Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6951', 'Data/Zenodo/NES_034_S02_20191009_170000.flac', '3585.0', '3585.6', '2881', '5423', 'yeceup1', None, None, 10.11, -84.52, 'Soundscape', 'Creative Commons Attribution 4.0 International Public License', 'https://zenodo.org/record/7525349', '17:59:45']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import date, datetime, time, timedelta\n",
    "\n",
    "for subset in subsets:\n",
    "    ID=0\n",
    "    with open(f'{annotations_path}Zenodo/{subset}_annotations.csv', newline='') as annotations:\n",
    "        reader = csv.DictReader(annotations) \n",
    "        with open(f\"{metadata_path}{subset}_metadata.csv\",\"w\",newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(columns)\n",
    "            for sample in reader:\n",
    "                #filter out unknown birds (in the case of zenodo these are all marked as ????)\n",
    "                if sample[\"Species eBird Code\"] == \"????\":\n",
    "                    continue\n",
    "\n",
    "                # Some of the subsets used multiple recording sights\n",
    "                if subset in [\"UHH\",\"PER\",\"NES\"]:\n",
    "                    #This part of the filename denotes the Recording Sight\n",
    "                    sight = int(sample['Filename'][9:11])\n",
    "                else:\n",
    "                    sight = 0\n",
    "\n",
    "                #start time of the recording\n",
    "                #note that the date is irrelevant\n",
    "                if subset in [\"HSN\",\"SNE\",\"SSW\"]:\n",
    "                    t = sample['Filename'][17:23]\n",
    "                else:\n",
    "                    t = sample['Filename'][21:27]\n",
    "                start_time = time(int(t[0:2]),int(t[2:4]),int(t[4:6]))\n",
    "                local_time = datetime.combine(date.today(),start_time)\n",
    "                #the start of the actual bird sound is relative to the audiofile\n",
    "                local_time+=timedelta(seconds=int(float(sample['Start Time (s)'])))\n",
    "                row = []\n",
    "                row.append(str(ID))#id\n",
    "                row.append(f\"Data/Zenodo/{sample['Filename']}\")#filepath\n",
    "                row.append(sample[\"Start Time (s)\"])#start_time\n",
    "                row.append(sample[\"End Time (s)\"])#end_time\n",
    "                row.append(sample[\"Low Freq (Hz)\"])#low_freq\n",
    "                row.append(sample[\"High Freq (Hz)\"])#high_freq\n",
    "                row.append(sample[\"Species eBird Code\"])#ebird_code\n",
    "                row.append(None)#call_type\n",
    "                row.append(None)#sex\n",
    "                row.append(coordinates[subset][sight][0])#lat\n",
    "                row.append(coordinates[subset][sight][1])#long\n",
    "                row.append(\"Soundscape\")#microphone\n",
    "                row.append(\"Creative Commons Attribution 4.0 International Public License\")#license\n",
    "                row.append(sources[subset])#source\n",
    "                row.append(str(local_time.time()))#local_time\n",
    "                writer.writerow(row)\n",
    "                ID += 1\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Powdermill\n",
    "The powdermill dataset is also a **Zenodo** dataset, but it must be processed differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16051', 'Data/Powdermill/Recording_4_Segment_10.WAV', '293.635281287', '295.32619025', '1982.2', '4870.6', 'eastow', None, None, 40.1602, -79.2719, 'Soundscape (AudioMoths)', 'Creative Commons Zero v1.0 Universal', 'https://zenodo.org/record/4656848', '07:13:53']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import date, datetime, time, timedelta\n",
    "\n",
    "start_times = {\"Recording_1\":time(5,32), \"Recording_2\":time(5,32), \n",
    "               \"Recording_3\":time(5,17), \"Recording_4\":time(6,19)}\n",
    "folders = [\"Recording_1\", \"Recording_2\", \"Recording_3\", \"Recording_4\"]\n",
    "\n",
    "ID=0\n",
    "other_sounds=[]\n",
    "with open(f\"{metadata_path}POW_metadata.csv\",\"w\",newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(columns)\n",
    "    for folder in folders:\n",
    "        path = f\"{annotations_path}Powdermill/{folder}/\"\n",
    "        annotations = [name for name in os.listdir(path)]\n",
    "        for annotation_file in annotations:\n",
    "            with open(f'{path}{annotation_file}', newline='') as annotations:\n",
    "                reader = csv.DictReader(annotations, delimiter='\\t') \n",
    "                for sample in reader:                         \n",
    "                    #Samples that are not Birds are removed\n",
    "                    bird = sample[\"Species\"]\n",
    "                    if bird in alpha_to_ebird:\n",
    "                        bird = alpha_to_ebird[bird]\n",
    "                    else:\n",
    "                        other_sounds.append(bird)\n",
    "                        continue\n",
    "                    \n",
    "                    #For uniformity replace NA and \"\" with None\n",
    "                    for key in sample.keys():\n",
    "                        if sample[key] == \"NA\" or sample[key]==\"\":\n",
    "                            sample[key] = None\n",
    "                    \n",
    "                    #start time of the recording\n",
    "                    #note that the date is irrelevant\n",
    "                    local_time = datetime.combine(date.today(),start_times[folder])\n",
    "                    #each recording is split into segments in 5 minute intervals\n",
    "                    segment = int(annotation_file[20:22])\n",
    "                    local_time+=timedelta(minutes=segment*5)\n",
    "                    #the start of the actual bird sound is relative to the audiofile\n",
    "                    local_time+=timedelta(seconds=int(float(sample['Begin Time (s)'])))\n",
    "\n",
    "                    row = []\n",
    "                    row.append(str(ID))#id\n",
    "                    audio_name = f\"{folder}_Segment_{annotation_file[20:22]}.WAV\"\n",
    "                    row.append(f\"Data/Powdermill/{audio_name}\")#filepath\n",
    "                    row.append(sample['Begin Time (s)'])#start_time\n",
    "                    row.append(sample['End Time (s)'])#end_time\n",
    "                    row.append(sample['Low Freq (Hz)'])#low_freq\n",
    "                    row.append(sample['High Freq (Hz)'])#high_freq\n",
    "                    row.append(bird)#ebird_code\n",
    "                    row.append(None)#call_type\n",
    "                    row.append(None)#sex\n",
    "                    row.append(40.1602)#lat\n",
    "                    row.append(-79.2719)#long\n",
    "                    row.append(\"Soundscape (AudioMoths)\")#microphone\n",
    "                    row.append(\"Creative Commons Zero v1.0 Universal\")#license\n",
    "                    row.append(\"https://zenodo.org/record/4656848\")#source\n",
    "                    row.append(str(local_time.time()))#local_time\n",
    "                    writer.writerow(row)\n",
    "                    ID += 1\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIPS4BPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5492', 'Data/NIPS4BPlus/nips4b_birds_trainfile344.wav', '0.391836735', 0.59138322, None, None, 'spofly1', 'call', None, None, None, 'Soundscape (SMX-US)', None, 'https://figshare.com/articles/dataset/Transcriptions_of_NIPS4B_2013_Bird_Challenge_Training_Dataset/6798548', None]\n",
      "5493 rows created\n",
      "282 unknown labels\n"
     ]
    }
   ],
   "source": [
    "import csv, os\n",
    "from datetime import date, datetime, time, timedelta\n",
    "\n",
    "annotation_files = [name for name in os.listdir(f\"{annotations_path}NIPS4BPlus/\")]\n",
    "ID=0\n",
    "unknown = 0\n",
    "with open(f\"{metadata_path}NIPS4BPlus_metadata.csv\",\"w\",newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(columns)\n",
    "    for annotation_file in annotation_files:\n",
    "        with open(f'{annotations_path}NIPS4BPlus/{annotation_file}', newline='') as annotation_f:\n",
    "            reader = csv.DictReader(annotation_f, fieldnames = [\"start_time\",\"duration\",\"label\"]) \n",
    "            for sample in reader:\n",
    "                \n",
    "                if sample[\"label\"]==\"Unknown\":\n",
    "                    unknown+=1\n",
    "                    continue\n",
    "\n",
    "                row = []\n",
    "                row.append(str(ID))#id\n",
    "                row.append(f\"Data/NIPS4BPlus/nips4b_birds_trainfile{annotation_file[-7:-4]}.wav\")#filepath\n",
    "                row.append(sample[\"start_time\"])#start_time\n",
    "                row.append(float(sample[\"start_time\"])+float(sample[\"duration\"]))#end_time\n",
    "                row.append(None)#low_freq\n",
    "                row.append(None)#high_freq\n",
    "                row.append(nips_to_ebird[sample[\"label\"]])#ebird_code\n",
    "                row.append(sample[\"label\"][-4:])#call_type\n",
    "                row.append(None)#sex\n",
    "                row.append(None)#lat\n",
    "                row.append(None)#long\n",
    "                row.append(\"Soundscape (SMX-US)\")#microphone\n",
    "                row.append(None)#license\n",
    "                row.append(\"https://figshare.com/articles/dataset/Transcriptions_of_NIPS4B_2013_Bird_Challenge_Training_Dataset/6798548\")#source\n",
    "                row.append(None)#local_time\n",
    "                writer.writerow(row)\n",
    "                ID += 1\n",
    "print(row)\n",
    "print(f\"{ID} rows created\")\n",
    "print(f\"{unknown} unknown labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bird-DB\n",
    "The following blocks build the Bird-DB metadata. The Bird-DB.pkl file is required and can be build in usefull_code.ipynb\n",
    "The columns of the bird_db are:\n",
    "\"track_name\",\"microphone\",\"sample_rate\",\"recording_date\",\"recording_time\",\"recording_length\",\n",
    "\"audio_file\", \"importance\",\"quality_rating\", \"common_name\", \"sex\", \"age_class\", \n",
    "\"certainty_of_species\",\"lat_deg\",\"lat_min\",\"lat_sec\",\"lat_orientation\",\"long_deg\",\n",
    "\"long_min\",\"long_sec\",\"long_orientation\", \"country\", \"number_of_phrases\", \"textgrid_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textgrid\n",
      "  Downloading TextGrid-1.5-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: textgrid\n",
      "Successfully installed textgrid-1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install textgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 textgrid-files where not downloadable\n"
     ]
    }
   ],
   "source": [
    "import pickle, textgrid, csv\n",
    "from pathlib import Path\n",
    "from datetime import time, timedelta\n",
    "\n",
    "# Converts degrees, minuts seconds to lat/long\n",
    "def dms2dd(degrees, minutes, seconds, direction):\n",
    "    dd = float(degrees) + float(minutes)/60 + float(seconds)/(60*60)\n",
    "    if direction == 'W' or direction == 'S':\n",
    "        dd *= -1\n",
    "    return dd\n",
    "\n",
    "with open(f\"{annotations_path}Bird-DB.pkl\",\"rb\") as f:\n",
    "    bird_db = pickle.load(f)\n",
    "\n",
    "\n",
    "#Change audio-paths to audio name\n",
    "bird_db[\"audio_file\"]=bird_db[\"audio_file\"].apply(lambda path : Path(path).name)\n",
    "\n",
    "#Change textgrid-paths to local paths\n",
    "bird_db[\"textgrid_file\"]=bird_db[\"textgrid_file\"].apply(lambda path : f\"./{annotations_path}Bird-DB/{Path(path).name}\")\n",
    "\n",
    "#Some textgrid-files did not exist (404 error when opening link)\n",
    "count = 0\n",
    "for index, row in bird_db.iterrows():\n",
    "    with open(row[\"textgrid_file\"],\"r\") as f:\n",
    "        if '<title>404 Not Found</title>' in f.read():\n",
    "            row[\"textgrid_file\"]=None \n",
    "            count += 1\n",
    "print(f\"{count} textgrid-files where not downloadable\")\n",
    "\n",
    "with open(f\"{metadata_path}BirdDB_metadata.csv\",\"w\",newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(columns)\n",
    "    #Each row in the bird_db corresponds to one species in a specific audio-file\n",
    "    #Each row has a textgrid-file which specifes, where the bird-calls occur\n",
    "    ID=0\n",
    "    for index, input_row in bird_db.iterrows():\n",
    "        if input_row[\"textgrid_file\"] is None:\n",
    "            continue\n",
    "\n",
    "        #each input_row anotates a specific bird\n",
    "        bird = input_row[\"common_name\"]\n",
    "        if bird not in common_to_ebird:\n",
    "            #Unknown Bird\n",
    "            print(f\"ebird code for {bird} not known\")\n",
    "            continue\n",
    "        bird = common_to_ebird[bird]\n",
    "\n",
    "        # For eficiency some calclulations can be done before iteration over the textgrid entries\n",
    "        t = input_row[\"recording_time\"].split(\":\")\n",
    "        t = map(int, t)\n",
    "        #start time of the recording\n",
    "        #note that the date is irrelevant\n",
    "        t = datetime.combine(date.today(),time(*t))\n",
    "        #The annotators seem to have gotten the orientations of the locations wrong at times\n",
    "        #All recordings where done in the USA (California and Wyoming)\n",
    "        #Therefore lat_orientation must be N and long_orientation must be W\n",
    "        lat_dms = [input_row[key] for key in [\"lat_deg\",\"lat_min\",\"lat_sec\"]]\n",
    "        lat_dms.append(\"N\")\n",
    "        long_dms = [input_row[key] for key in [\"long_deg\",\"long_min\",\"long_sec\"]]\n",
    "        long_dms.append(\"W\")\n",
    "        if \"\" in lat_dms or \"\" in long_dms:\n",
    "            lat = None\n",
    "            long = None\n",
    "        else:\n",
    "            lat = dms2dd(*lat_dms)\n",
    "            long = dms2dd(*long_dms)\n",
    "\n",
    "        #Now iterate over each item and interval in the given textgrid file\n",
    "        tg = textgrid.TextGrid.fromFile(input_row[\"textgrid_file\"])\n",
    "        for items in tg:\n",
    "            for interval in items:\n",
    "                if interval.mark == \"\":\n",
    "                    # the bird is not detected in this interval\n",
    "                    continue\n",
    "                elif interval.mark == \"~1\":\n",
    "                    #I assume this means that the bird is hardly audible here\n",
    "                    #I therefore think, that this should be removed.\n",
    "                    continue\n",
    "                row = []\n",
    "                row.append(str(ID))#id\n",
    "                row.append(f\"Data/BirdDB/{input_row['audio_file']}\")#filepath\n",
    "                row.append(interval.minTime)#start_time\n",
    "                row.append(interval.maxTime)#end_time\n",
    "                row.append(None)#low_freq\n",
    "                row.append(None)#high_freq\n",
    "                row.append(bird)#ebird_code\n",
    "                row.append(None)#call_type\n",
    "                row.append(input_row[\"sex\"])#sex\n",
    "                row.append(lat)#lat\n",
    "                row.append(long)#long\n",
    "                row.append(input_row[\"microphone\"])#microphone\n",
    "                row.append(\"Attribution-NonCommercial-NoDerivs 4.0 International\")#license\n",
    "                row.append(\"https://doi.org/10.1016/j.ecoinf.2015.01.007\")#source\n",
    "                local_time=t+timedelta(seconds=interval.minTime)\n",
    "                row.append(local_time.time())#local_time\n",
    "                writer.writerow(row)\n",
    "                ID += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OekoFor\n",
    "The oekofor dataset still has some dificulties:\n",
    "- time can be extracted from the filenames (in Greenwich Mean Time)\n",
    "- the rough locantion can be extracted from the folder names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
