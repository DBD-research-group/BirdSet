{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose\n",
    "This file is used to generate the metadata files for diverse datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing Data\n",
    "Before running this notebook make shure that the data is in folders corresponding to the dataset names. The folder structure of the datafolder should be as follows:\n",
    "- data_path\n",
    "    - Data\n",
    "        - OekoFor\n",
    "            - 2016_Scotland\n",
    "                - *audio_files*\n",
    "            - ...\n",
    "        - Zenodo\n",
    "            - *audio_files*\n",
    "        - Powdermill\n",
    "            - Recording_1\n",
    "                - *audio_files*\n",
    "            - ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The path to the folder containing all audiofiles, this folder should be named Data\n",
    "#If Data is in the same directory as this notebook the data_path should be the empty string\n",
    "data_path = \"/data-project/DeepBirdDetect/BirdSet/\"\n",
    "#The path to where annotation files are stored\n",
    "annotations_path = \"Annotations/\"\n",
    "#The path to where the gernerated metadata should be stored\n",
    "metadata_path = \"Metadata/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 79 out of 2326 entrys in the Alpha codes which I could not translate to ebirdcodes\n",
      "There are 0 out of 2247 entrys in the NIPS4BPlus codes which I could not translate to ebirdcodes\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build an empty dictionary with the colmun-names as keys. For each dataset (i.e. Oeko4, Powdermill, etc.) the empty_dataset is deepcopied and filled.\n",
    "The resulting dataset can then be converted into a HuggingFace Dataset object.\n",
    "Also build dictionarys to translate different bird-codes\n",
    "\"\"\"\n",
    "\n",
    "columns=[\"id\", \"filepath\", \"start_time\", \"end_time\", \"low_freq\", \"high_freq\", \"ebird_code\"\n",
    "         , \"call_type\", \"sex\", \"lat\", \"long\", \"microphone\", \"license\", \"source\", \"local_time\"]\n",
    "\"\"\"\n",
    "Read the taxonomy from the csv file and convert it to the e_bird_codes dictionary.\n",
    "common_to_ebird maps common_names to e-bird-codes\n",
    "\"\"\"\n",
    "import csv\n",
    "common_to_ebird = {} #This dict saves the e-bird-code for each common name\n",
    "with open('ebird_taxonomy_v2022.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        common_name = row[3]\n",
    "        e_bird_code = row[2]\n",
    "        common_to_ebird[common_name]=e_bird_code\n",
    "\n",
    "\"\"\"\n",
    "The sci_to_ebird dictionary maps each scientific (latin) name to the corresponding e-bird-code.\n",
    "\"\"\"\n",
    "import csv\n",
    "sci_to_ebird = {} #This dict saves the e-bird-code for each common name\n",
    "with open('ebird_taxonomy_v2022.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        sci_name = row[4]\n",
    "        e_bird_code = row[2]\n",
    "        sci_to_ebird[sci_name]=e_bird_code\n",
    "\n",
    "\"\"\"\n",
    "The ebird_to_common dictionary maps each e-bird-code to the corresponding common name.\n",
    "\"\"\"\n",
    "ebird_to_common = {} #This dict saves the e-bird-code for each common name\n",
    "with open('ebird_taxonomy_v2022.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        common_name = row[3]\n",
    "        e_bird_code = row[2]\n",
    "        ebird_to_common[e_bird_code]=common_name\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The alpha_to_ebird dictionary maps each alpha-code to the corresponding ebird-code.\n",
    "\"\"\"\n",
    "alpha_to_ebird = {} #This dict saves the alpha-code for each e_bird_code\n",
    "not_found = []\n",
    "non_bird_sound = []\n",
    "with open('AlphaCodes.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "        common_name = row[3]\n",
    "        alpha_code = row[1]\n",
    "        sci_name = row[4]\n",
    "\n",
    "        #I am pretty shure that AMGP is a typo in the AlphaCodes.csv\n",
    "        #AMGO does not appear as a label for any sample\n",
    "        #AMGO does appear as a label for 62 samples but is not in AlphaCodes.csv\n",
    "        if alpha_code == \"AMGP\":\n",
    "            alpha_code = \"AMGO\"\n",
    "\n",
    "        if sci_name in sci_to_ebird.keys():\n",
    "            alpha_to_ebird[alpha_code]=sci_to_ebird[sci_name]\n",
    "        elif common_name in common_to_ebird.keys():\n",
    "            #If the scientific name can not be found try the common name\n",
    "            alpha_to_ebird[alpha_code]=common_to_ebird[common_name]\n",
    "        else:\n",
    "            not_found.append(f\"{common_name}/ {sci_name}\")\n",
    "print(f\"There are {len(not_found)} out of {len(not_found)+len(alpha_to_ebird.keys())} entrys in the Alpha codes which I could not translate to ebirdcodes\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "The NIPS4BPlus dataset uses it's verry own bird names. The nips_to_ebird dictionary maps these bird names to the corresponding ebird-codes.\n",
    "\"\"\"\n",
    "nips_to_ebird = {} #This dict saves the nips4bplus names for each e_bird_code\n",
    "nips_to_ebird[\"Human\"]=\"not_a_bird\"\n",
    "not_found = []\n",
    "with open('nips4b_birdchallenge_espece_list.csv', newline='') as csvfile:\n",
    "    taxonomy = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "    first = True\n",
    "    for row in taxonomy:\n",
    "        if first:\n",
    "            first = False\n",
    "            continue\n",
    "\n",
    "        common_name = row[2]\n",
    "        nips_code = row[1]\n",
    "        sci_name = row[3]\n",
    "        type = row[4]\n",
    "\n",
    "        #fixing a misspelled name\n",
    "        if sci_name == \"lullula arborea\":\n",
    "            sci_name = \"Lullula arborea\"\n",
    "        \n",
    "        #fixing synonimous scientific names\n",
    "        if sci_name == \"Sylvia cantillans\":\n",
    "            sci_name = \"Curruca cantillans\"\n",
    "        if sci_name == \"Sylvia melanocephala\":\n",
    "            sci_name = \"Curruca melanocephala\"\n",
    "\n",
    "        if type != \"bird\":\n",
    "            #This is not a bird sound\n",
    "            nips_to_ebird[nips_code]=\"not_a_bird\"\n",
    "        elif sci_name in sci_to_ebird.keys():\n",
    "            nips_to_ebird[nips_code]=sci_to_ebird[sci_name]\n",
    "        elif common_name in common_to_ebird.keys():\n",
    "            #If the scientific name can not be found try the common name\n",
    "            nips_to_ebird[nips_code]=common_to_ebird[common_name]    \n",
    "        else:\n",
    "            not_found.append(f\"{common_name}/ {sci_name}\")\n",
    "print(f\"There are {len(not_found)} out of {len(not_found)+len(alpha_to_ebird.keys())} entrys in the NIPS4BPlus codes which I could not translate to ebirdcodes\")\n",
    "for x in not_found:\n",
    "    print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zenodo\n",
    "The following Blocks build the Zenodo dataset and adds it to the list of datasets. The Zenodo dataset consists of 5 Datasets, namely HSN, SNE, UHH, PER, SSW and NES. These are stored as individual metadata-files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Constants\n",
    "The following codeblock defines some required constants. These include the folder names for the 5 Datasets, their respective sources, as well as their respective cooridinates (Latitude, Longitude)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsets = [\"HSN\", \"SNE\", \"UHH\", \"PER\", \"SSW\", \"NES\"]\n",
    "\n",
    "sources={\"HSN\": \"https://zenodo.org/record/7525805\",\n",
    "        \"SNE\": \"https://zenodo.org/record/7050014\",\n",
    "        \"UHH\": \"https://zenodo.org/record/7078499\",\n",
    "        \"PER\": \"https://zenodo.org/record/7079124\",\n",
    "        \"SSW\": \"https://zenodo.org/record/7079380\",\n",
    "        \"NES\": \"https://zenodo.org/record/7525349\"}\n",
    "\"\"\"\n",
    "Coordinates are saved as [latitude, logitude]. Some of the datasets contain multiple recording sights.\n",
    "I filled these in by hand, as the different datasets had used different formats which had to be \n",
    "converted to (Lat,Lon).\n",
    "\"\"\"\n",
    "coordinates={\"HSN\": {0:[37.0, -118.5]},\n",
    "             \"SNE\": {0:[38.49, -119.95]},\n",
    "             \"UHH\": {1:[19.801668, -155.609444],\n",
    "                     2:[19.792975, -155.321332],\n",
    "                     3:[19.46647, -155.582011],\n",
    "                     4:[19.820609, -155.468097]},\n",
    "             \"PER\": {1:[-12.542578, -69.062050],\n",
    "                     2:[-12.541925, -69.058642],\n",
    "                     4:[-12.537814, -69.054308],\n",
    "                     5:[-12.535539, -69.06674],\n",
    "                     6:[-12.532981, -69.049864],\n",
    "                     8:[-12.529858, -69.046164],\n",
    "                     10:[-12.522983, -69.046822]},\n",
    "             \"SSW\": {0:[42.4768, -76.4527]},\n",
    "             \"NES\": {1:[5.59,-75.85],\n",
    "                     2:[10.11,-84.52]}\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build Dataset\n",
    "The following block builds a dictionary from the data and converts it into a HuggingFace Dataset Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['6951', 'Data/Zenodo/NES_034_S02_20191009_170000.flac', '3585.0', '3585.6', '2881', '5423', 'yeceup1', None, None, 10.11, -84.52, 'Soundscape', 'Creative Commons Attribution 4.0 International Public License', 'https://zenodo.org/record/7525349', '17:59:45']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import date, datetime, time, timedelta\n",
    "\n",
    "for subset in subsets:\n",
    "    ID=0\n",
    "    with open(f'{annotations_path}Zenodo/{subset}_annotations.csv', newline='') as annotations:\n",
    "        reader = csv.DictReader(annotations) \n",
    "        with open(f\"{metadata_path}{subset}_metadata.csv\",\"w\",newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow(columns)\n",
    "            for sample in reader:\n",
    "                #filter out unknown birds (in the case of zenodo these are all marked as ????)\n",
    "                if sample[\"Species eBird Code\"] == \"????\":\n",
    "                    continue\n",
    "\n",
    "                # Some of the subsets used multiple recording sights\n",
    "                if subset in [\"UHH\",\"PER\",\"NES\"]:\n",
    "                    #This part of the filename denotes the Recording Sight\n",
    "                    sight = int(sample['Filename'][9:11])\n",
    "                else:\n",
    "                    sight = 0\n",
    "\n",
    "                #start time of the recording\n",
    "                #note that the date is irrelevant\n",
    "                if subset in [\"HSN\",\"SNE\",\"SSW\"]:\n",
    "                    t = sample['Filename'][17:23]\n",
    "                else:\n",
    "                    t = sample['Filename'][21:27]\n",
    "                start_time = time(int(t[0:2]),int(t[2:4]),int(t[4:6]))\n",
    "                local_time = datetime.combine(date.today(),start_time)\n",
    "                #the start of the actual bird sound is relative to the audiofile\n",
    "                local_time+=timedelta(seconds=int(float(sample['Start Time (s)'])))\n",
    "                row = []\n",
    "                row.append(str(ID))#id\n",
    "                row.append(f\"Data/Zenodo/{sample['Filename']}\")#filepath\n",
    "                row.append(sample[\"Start Time (s)\"])#start_time\n",
    "                row.append(sample[\"End Time (s)\"])#end_time\n",
    "                row.append(sample[\"Low Freq (Hz)\"])#low_freq\n",
    "                row.append(sample[\"High Freq (Hz)\"])#high_freq\n",
    "                row.append(sample[\"Species eBird Code\"])#ebird_code\n",
    "                row.append(None)#call_type\n",
    "                row.append(None)#sex\n",
    "                row.append(coordinates[subset][sight][0])#lat\n",
    "                row.append(coordinates[subset][sight][1])#long\n",
    "                row.append(\"Soundscape\")#microphone\n",
    "                row.append(\"Creative Commons Attribution 4.0 International Public License\")#license\n",
    "                row.append(sources[subset])#source\n",
    "                row.append(str(local_time.time()))#local_time\n",
    "                writer.writerow(row)\n",
    "                ID += 1\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Powdermill\n",
    "The powdermill dataset is also a **Zenodo** dataset, but it must be processed differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['16051', 'Data/Powdermill/Recording_4_Segment_10.WAV', '293.635281287', '295.32619025', '1982.2', '4870.6', 'eastow', None, None, 40.1602, -79.2719, 'Soundscape (AudioMoths)', 'Creative Commons Zero v1.0 Universal', 'https://zenodo.org/record/4656848', '07:13:53']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import date, datetime, time, timedelta\n",
    "\n",
    "start_times = {\"Recording_1\":time(5,32), \"Recording_2\":time(5,32), \n",
    "               \"Recording_3\":time(5,17), \"Recording_4\":time(6,19)}\n",
    "folders = [\"Recording_1\", \"Recording_2\", \"Recording_3\", \"Recording_4\"]\n",
    "\n",
    "ID=0\n",
    "other_sounds=[]\n",
    "with open(f\"{metadata_path}POW_metadata.csv\",\"w\",newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(columns)\n",
    "    for folder in folders:\n",
    "        path = f\"{annotations_path}Powdermill/{folder}/\"\n",
    "        annotations = [name for name in os.listdir(path)]\n",
    "        for annotation_file in annotations:\n",
    "            with open(f'{path}{annotation_file}', newline='') as annotations:\n",
    "                reader = csv.DictReader(annotations, delimiter='\\t') \n",
    "                for sample in reader:                         \n",
    "                    #Samples that are not Birds are removed\n",
    "                    bird = sample[\"Species\"]\n",
    "                    if bird in alpha_to_ebird:\n",
    "                        bird = alpha_to_ebird[bird]\n",
    "                    else:\n",
    "                        other_sounds.append(bird)\n",
    "                        continue\n",
    "                    \n",
    "                    #For uniformity replace NA and \"\" with None\n",
    "                    for key in sample.keys():\n",
    "                        if sample[key] == \"NA\" or sample[key]==\"\":\n",
    "                            sample[key] = None\n",
    "                    \n",
    "                    #start time of the recording\n",
    "                    #note that the date is irrelevant\n",
    "                    local_time = datetime.combine(date.today(),start_times[folder])\n",
    "                    #each recording is split into segments in 5 minute intervals\n",
    "                    segment = int(annotation_file[20:22])\n",
    "                    local_time+=timedelta(minutes=segment*5)\n",
    "                    #the start of the actual bird sound is relative to the audiofile\n",
    "                    local_time+=timedelta(seconds=int(float(sample['Begin Time (s)'])))\n",
    "\n",
    "                    row = []\n",
    "                    row.append(str(ID))#id\n",
    "                    audio_name = f\"{folder}_Segment_{annotation_file[20:22]}.WAV\"\n",
    "                    row.append(f\"Data/Powdermill/{audio_name}\")#filepath\n",
    "                    row.append(sample['Begin Time (s)'])#start_time\n",
    "                    row.append(sample['End Time (s)'])#end_time\n",
    "                    row.append(sample['Low Freq (Hz)'])#low_freq\n",
    "                    row.append(sample['High Freq (Hz)'])#high_freq\n",
    "                    row.append(bird)#ebird_code\n",
    "                    row.append(None)#call_type\n",
    "                    row.append(None)#sex\n",
    "                    row.append(40.1602)#lat\n",
    "                    row.append(-79.2719)#long\n",
    "                    row.append(\"Soundscape (AudioMoths)\")#microphone\n",
    "                    row.append(\"Creative Commons Zero v1.0 Universal\")#license\n",
    "                    row.append(\"https://zenodo.org/record/4656848\")#source\n",
    "                    row.append(str(local_time.time()))#local_time\n",
    "                    writer.writerow(row)\n",
    "                    ID += 1\n",
    "print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NIPS4BPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5492', 'Data/NIPS4BPlus/nips4b_birds_trainfile344.wav', '0.391836735', 0.59138322, None, None, 'spofly1', 'call', None, None, None, 'Soundscape (SMX-US)', None, 'https://figshare.com/articles/dataset/Transcriptions_of_NIPS4B_2013_Bird_Challenge_Training_Dataset/6798548', None]\n",
      "5493 rows created\n",
      "282 unknown labels\n"
     ]
    }
   ],
   "source": [
    "import csv, os\n",
    "from datetime import date, datetime, time, timedelta\n",
    "annotation_files = [name for name in os.listdir(f\"{annotations_path}NIPS4BPlus/\")]\n",
    "ID=0\n",
    "unknown = 0\n",
    "with open(f\"{metadata_path}NIPS4BPlus_metadata.csv\",\"w\",newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(columns)\n",
    "    for annotation_file in annotation_files:\n",
    "        with open(f'{annotations_path}NIPS4BPlus/{annotation_file}', newline='') as annotation_f:\n",
    "            reader = csv.DictReader(annotation_f, fieldnames = [\"start_time\",\"duration\",\"label\"]) \n",
    "            for sample in reader:\n",
    "                \n",
    "                if sample[\"label\"]==\"Unknown\":\n",
    "                    unknown+=1\n",
    "                    continue\n",
    "\n",
    "                row = []\n",
    "                row.append(str(ID))#id\n",
    "                row.append(f\"Data/NIPS4BPlus/nips4b_birds_trainfile{annotation_file[-7:-4]}.wav\")#filepath\n",
    "                row.append(sample[\"start_time\"])#start_time\n",
    "                row.append(float(sample[\"start_time\"])+float(sample[\"duration\"]))#end_time\n",
    "                row.append(None)#low_freq\n",
    "                row.append(None)#high_freq\n",
    "                row.append(nips_to_ebird[sample[\"label\"]])#ebird_code\n",
    "                row.append(sample[\"label\"][-4:])#call_type\n",
    "                row.append(None)#sex\n",
    "                row.append(None)#lat\n",
    "                row.append(None)#long\n",
    "                row.append(\"Soundscape (SMX-US)\")#microphone\n",
    "                row.append(None)#license\n",
    "                row.append(\"https://figshare.com/articles/dataset/Transcriptions_of_NIPS4B_2013_Bird_Challenge_Training_Dataset/6798548\")#source\n",
    "                row.append(None)#local_time\n",
    "                writer.writerow(row)\n",
    "                ID += 1\n",
    "print(row)\n",
    "print(f\"{ID} rows created\")\n",
    "print(f\"{unknown} unknown labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BIRD DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in /home/jlange/.local/lib/python3.8/site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jlange/.local/lib/python3.8/site-packages (from bs4) (4.12.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jlange/.local/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting regex\n",
      "  Downloading regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "\u001b[K     |████████████████████████████████| 776 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: regex\n",
      "Successfully installed regex-2023.10.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bs4\n",
    "%pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "646\n"
     ]
    }
   ],
   "source": [
    "import pandas, regex\n",
    "from bs4 import BeautifulSoup\n",
    "with open(\"bird_db.html\", \"r\") as f:\n",
    "    res=\"\"\n",
    "    for row in f:\n",
    "        res+=row\n",
    "soup = BeautifulSoup(res, 'html.parser')\n",
    "table = soup.find('table')\n",
    "print(len(table))\n",
    "\n",
    "table_rows = table.find_all('tr')\n",
    "print(len(table_rows))\n",
    "\n",
    "data = []\n",
    "first = True\n",
    "for tr in table_rows:\n",
    "    if first:\n",
    "        first = False\n",
    "        continue\n",
    "    td = tr.find_all('td')\n",
    "    row = []\n",
    "    for entry in td:\n",
    "        if \"Click to play\" in entry.text:\n",
    "            subpath = regex.findall(\"\\\".*?\\\"\", str(entry))[0]\n",
    "            row.append(f\"http://taylor0.biology.ucla.edu/birdDBQuery/{subpath[3:-1]}\")\n",
    "        elif \"Files_TextGrids\" in entry.text:\n",
    "            row.append(f\"http://taylor0.biology.ucla.edu/birdDBQuery/Files/{entry.text}\")\n",
    "        else:\n",
    "            row.append(entry.text)\n",
    "    data.append(row)\n",
    "\n",
    "df = pandas.DataFrame(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(645, 23)\n",
      "track_name: tCOMM09-1\n",
      "microphone: Sennheiser omnidirectional with Telinga parabolic reflector\n",
      "sample_rate: 44\n",
      "recording_date: 2009-03-21\n",
      "recording_time: 08:25:00\n",
      "recording_length: 00:02:30\n",
      "audio_file: http://taylor0.biology.ucla.edu/birdDBQuery/Files/Tracks/2009/March/CATH1.WAV\n",
      "importance: Primary subject\n",
      "quality_rating: 4\n",
      "common_name: California Thrasher\n",
      "sex: Male(s)\n",
      "age_class: Reproductive adult\n",
      "certainty_of_species: 5\n",
      "lat_deg: 38\n",
      "lat_min: 15\n",
      "lat_sec: 17.95\n",
      "lat_orientation: N\n",
      "long_deg: 120\n",
      "long_min: 53\n",
      "long_sec: 5.43\n",
      "long_orientation: W\n",
      "number_of_phrases: 383\n",
      "textgrid_file: http://taylor0.biology.ucla.edu/birdDBQuery/Files/Files_TextGrids/2009/March/CATH1.TextGrid\n"
     ]
    }
   ],
   "source": [
    "columns=[\"track_name\",\"microphone\",\"sample_rate\",\"recording_date\",\"recording_time\",\"recording_length\",\n",
    "         \"audio_file\", \"importance\",\"quality_rating\", \"common_name\", \"sex\", \"age_class\", \n",
    "         \"certainty_of_species\",\"lat_deg\",\"lat_min\",\"lat_sec\",\"lat_orientation\",\"long_deg\",\n",
    "         \"long_min\",\"long_sec\",\"long_orientation\", \"number_of_phrases\", \"textgrid_file\"]\n",
    "bird_db = df.iloc[:, [0,3,5,8,9,10,11,13,14,16,17,18,20,21,22,23,24,25,26,27,28,41,42]]\n",
    "bird_db.columns = columns\n",
    "print(bird_db.shape)\n",
    "for c in columns:\n",
    "    print(f\"{c}: {bird_db[c][0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "def count_occurrences(df, key):\n",
    "    dict = {}\n",
    "    for entry in df[key]:\n",
    "        if entry in dict.keys():\n",
    "            dict[entry]+=1\n",
    "        else:\n",
    "            dict[entry]=1\n",
    "    return dict\n",
    "print(count_occurrences(bird_db,\"audio_file\").values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bird_db_textgrid_files.txt\",\"w\") as f:\n",
    "    for url in bird_db[\"textgrid_file\"]:\n",
    "        f.write(f\"{url}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316    tFTANN1405-1616\n",
      "Name: track_name, dtype: object\n",
      "316    Sennheiser omnidirectional with Telinga parabo...\n",
      "Name: microphone, dtype: object\n",
      "316    44\n",
      "Name: sample_rate, dtype: object\n",
      "316    2014-06-02\n",
      "Name: recording_date, dtype: object\n",
      "316    09:35:00\n",
      "Name: recording_time, dtype: object\n",
      "316    00:16:34\n",
      "Name: recording_length, dtype: object\n",
      "316    http://taylor0.biology.ucla.edu/birdDBQuery/Fi...\n",
      "Name: audio_file, dtype: object\n",
      "316    Primary subject\n",
      "Name: importance, dtype: object\n",
      "316    \n",
      "Name: quality_rating, dtype: object\n",
      "316    Cassin's Vireo\n",
      "Name: common_name, dtype: object\n",
      "316    Male(s)\n",
      "Name: sex, dtype: object\n",
      "316    Reproductive adult\n",
      "Name: age_class, dtype: object\n",
      "316    \n",
      "Name: certainty_of_species, dtype: object\n",
      "316    38\n",
      "Name: lat_deg, dtype: object\n",
      "316    29\n",
      "Name: lat_min, dtype: object\n",
      "316    21.9\n",
      "Name: lat_sec, dtype: object\n",
      "316    \n",
      "Name: lat_orientation, dtype: object\n",
      "316    120\n",
      "Name: long_deg, dtype: object\n",
      "316    37\n",
      "Name: long_min, dtype: object\n",
      "316    41.2\n",
      "Name: long_sec, dtype: object\n",
      "316    \n",
      "Name: long_orientation, dtype: object\n",
      "316    330\n",
      "Name: number_of_phrases, dtype: object\n",
      "316    http://taylor0.biology.ucla.edu/birdDBQuery/Fi...\n",
      "Name: textgrid_file, dtype: object\n"
     ]
    }
   ],
   "source": [
    "filtered = bird_db.loc[bird_db['audio_file'] == \"http://taylor0.biology.ucla.edu/birdDBQuery/Files/Tracks/2014/Jun/1617.WAV\"]\n",
    "for column in  filtered:\n",
    "    print(f\"{filtered[column]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OekoFor\n",
    "The oekofor dataset still has some dificulties:\n",
    "- time can be extracted from the filenames (in Greenwich Mean Time)\n",
    "- the rough locantion can be extracted from the folder names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
