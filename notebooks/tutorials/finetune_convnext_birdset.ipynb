{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune the ConvNext BirdSet model on a custom dataset\n",
    "\n",
    "This notebook demonstrates how to finetune the ConvNext BirdSet model on a custom dataset. The custom dataset used as an example is [ESC50 dataset](https://github.com/karolpiczak/ESC-50), which contains 2000 environmental audio recordings. We will use Lightning as a high-level interface for PyTorch to simplify the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR='../../data_birdset'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESC50 datamodule\n",
    "First we define a datamodule for the ESC50 dataset. The datamodule will download the dataset, split it into training and validation sets, here augmentations could be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['audio', 'labels'],\n",
      "    num_rows: 1200\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from lightning import LightningDataModule\n",
    "from datasets import load_dataset, Audio\n",
    "from torch.utils.data import DataLoader\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "\n",
    "class ESC50DataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.resampler = torchaudio.transforms.Resample(orig_freq=44100, new_freq=32000)\n",
    "        self.train_dataset = None\n",
    "        self.test_dataset = None\n",
    "    \n",
    "    def _transforms(self, batch):\n",
    "        # collate audio\n",
    "        waveform_batch = [audio['array'] for audio in batch['audio']]\n",
    "        # TODO add data augmentation here\n",
    "        return {\"input_values\": waveform_batch, \"labels\": batch['labels']}\n",
    "\n",
    "\n",
    "    def prepare_data(self):\n",
    "        dataset = load_dataset(\n",
    "                path=\"ashraq/esc50\",\n",
    "                cache_dir=CACHE_DIR,\n",
    "        )\n",
    "        dataset = dataset.cast_column(\n",
    "            column=\"audio\",\n",
    "            feature=Audio(\n",
    "                sampling_rate=32000,\n",
    "                mono=True,\n",
    "                decode=True,\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        dataset = dataset.rename_column(\"target\", \"labels\")\n",
    "        # the ESC50 samples are split into 5 folds, select 4 folds for training and 1 fold for testing\n",
    "        self.train_dataset = dataset['train'].filter(lambda x: x['fold'] in [1, 2, 3, 0])\n",
    "        self.test_dataset = dataset['train'].filter(lambda x: x['fold'] == 4)\n",
    "        # rename target column to labels\n",
    "        self.train_dataset = self.train_dataset.select_columns([\"audio\", \"labels\"])\n",
    "        self.test_dataset = self.test_dataset.select_columns([\"audio\", \"labels\"])\n",
    "        self.train_dataset.set_transform(self._transforms)\n",
    "        self.test_dataset.set_transform(self._transforms)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "dm = ESC50DataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup('fit')\n",
    "print(dm.train_dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Module\n",
    "Next, we define a lightning module that loads the ConvNext BirdSet model, defines the training and testing step including logging the accuracy and loss. We use the ADAM optimizer and the CrossEntropyLoss as the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ConvNextForImageClassification were not initialized from the model checkpoint at DBD-research-group/ConvNeXT-Base-BirdSet-XCL and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([9736]) in the checkpoint and torch.Size([50]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([9736, 1024]) in the checkpoint and torch.Size([50, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from birdset import ConvNextBirdSet\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from lightning import LightningModule\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "class BirdsetLightningModule(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = ConvNextBirdSet(num_classes=50)\n",
    "        self.train_acc_metric = Accuracy(task=\"multiclass\", num_classes=50)\n",
    "        self.test_acc_metric = Accuracy(task=\"multiclass\", num_classes=50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def _step(self, batch):\n",
    "        x = batch[\"input_values\"]\n",
    "        y = batch[\"labels\"]\n",
    "        preprocessed = self.model.preprocess(x)\n",
    "        y_hat = self.model(preprocessed)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        return loss, y_hat\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, y_hat = self._step(batch)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        # update accuracy metric for training batch\n",
    "        self.train_acc_metric.update(y_hat, batch[\"labels\"])\n",
    "        acc = self.train_acc_metric.compute()\n",
    "        self.log(\"train_acc\", acc, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # reset the test accuracy metric at the end of testing\n",
    "        self.test_acc_metric.reset()\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        loss, y_hat = self._step(batch)\n",
    "        self.log(\"test_loss\", loss)\n",
    "        # update accuracy metric for test batch\n",
    "        self.test_acc_metric.update(y_hat, batch[\"labels\"])\n",
    "        acc = self.test_acc_metric.compute()\n",
    "        self.log(\"test_acc\", acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # reset the training accuracy metric at the end of the epoch\n",
    "        self.train_acc_metric.reset()\n",
    "\n",
    "    def on_test_epoch_end(self):\n",
    "        # reset the test accuracy metric at the end of testing\n",
    "        self.test_acc_metric.reset()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.model.parameters(), lr=5e-5)\n",
    "\n",
    "module = BirdsetLightningModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "\n",
      "  | Name             | Type               | Params | Mode \n",
      "----------------------------------------------------------------\n",
      "0 | model            | ConvNextBirdSet    | 87.6 M | train\n",
      "1 | train_acc_metric | MulticlassAccuracy | 0      | train\n",
      "2 | test_acc_metric  | MulticlassAccuracy | 0      | train\n",
      "----------------------------------------------------------------\n",
      "87.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.6 M    Total params\n",
      "350.454   Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "279       Modules in eval mode\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/birdset-xS3fZVNL-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=31` in the `DataLoader` to improve performance.\n",
      "/home/vscode/.cache/pypoetry/virtualenvs/birdset-xS3fZVNL-py3.10/lib/python3.10/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (38) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952a237c7001439c99b883c7833565a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "# define trainer\n",
    "from lightning import Trainer\n",
    "\n",
    "trainer = Trainer(max_epochs=10, accelerator=\"gpu\", devices=[0])\n",
    "\n",
    "# train the model\n",
    "trainer.fit(module, dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model\n",
    "Finally, we test the model on the test set and report the accuracy.\n",
    "0.89, not bad for a simple finetuning! See [paperswithcode](https://paperswithcode.com/sota/audio-classification-on-esc-50) for the state of the art on the ESC50 dataset.\n",
    "Keep in mind, that we are training on the first 4 folds and test on the 5th fold, so the results are not directly comparable to the state of the art as this envolves cross-validation on all 5 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bdd096bd20142e1be4923f700a40221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_acc          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8874237537384033     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5572055578231812     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_acc         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8874237537384033    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5572055578231812    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss': 0.5572055578231812, 'test_acc': 0.8874237537384033}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(module, dm.test_dataloader())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "birdset-xS3fZVNL-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
