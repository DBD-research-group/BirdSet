{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "5ed02a1b-72ee-475e-9794-a6c0396fea10",
            "metadata": {},
            "source": [
                "# BirdSet Data Pipeline Tutorial\n",
                "\n",
                "This Jupyter notebook provides a comprehensive guide to setting up and configuring a data pipeline tailored for bird classification in audio files. The tutorial is structured to walk you through each component of the pipeline, ensuring a clear understanding of its functionality and configuration. Whether you are processing raw audio data or spectrograms, this notebook aims to provide you with the necessary knowledge to efficiently set up your data pipeline."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0909c001-7d00-4a0f-a16c-c984e7d91740",
            "metadata": {},
            "source": [
                "## Installation\n",
                "\n",
                "### Prerequisites\n",
                "Before initiating the installation process of the BirdSet pipeline, it's crucial to ensure that your computing environment meets the following prerequisites:\n",
                "- **Python**: You should have Python version 3.10 or higher installed on your system.\n",
                "\n",
                "### Installation Steps\n",
                "The BirdSet pipeline can be installed using either of the two methods: via Conda with Pip, or using Poetry. Select the method that best suits your preference and follow the corresponding steps below.\n",
                "\n",
                "#### Using Conda and Pip\n",
                "\n",
                "1. **Create a Conda Environment**: Begin by setting up a dedicated environment for BirdSet. This is a best practice to manage dependencies and avoid potential conflicts with other packages in your system.\n",
                "\n",
                "   ```bash\n",
                "   conda create -n birdset python=3.10\n",
                "   ```\n",
                "\n",
                "   After the environment is successfully created, activate it:\n",
                "\n",
                "   ```bash\n",
                "   conda activate birdset\n",
                "   ```\n",
                "\n",
                "2. **Install BirdSet**: Proceed with cloning the BirdSet repository and installing the package in editable mode. This approach is beneficial as it allows any modifications you make to the BirdSet code to be reflected immediately without the need for reinstallation.\n",
                "\n",
                "   ```bash\n",
                "   git clone https://github.com/DBD-research-group/BirdSet.git\n",
                "   cd BirdSet\n",
                "   pip install -e .\n",
                "   ```\n",
                "\n",
                "#### Using Poetry\n",
                "\n",
                "1. **Clone the Repository**: Start with cloning the BirdSet repository to your local machine and navigate to the cloned directory.\n",
                "\n",
                "   ```bash\n",
                "   git clone https://github.com/DBD-research-group/BirdSet.git\n",
                "   cd BirdSet\n",
                "   ```\n",
                "\n",
                "2. **Configure Poetry**: Prepare the project for Poetry by renaming the `pyproject.poetry` file to `pyproject.toml`.\n",
                "\n",
                "   ```bash\n",
                "   mv pyproject.poetry pyproject.toml\n",
                "   ```\n",
                "\n",
                "3. **Install Dependencies and Activate Environment**: Install all the necessary dependencies with Poetry and then activate the Poetry shell environment.\n",
                "\n",
                "   ```bash\n",
                "   poetry install\n",
                "   poetry shell\n",
                "   ```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "41a4f398-f18d-42e4-a6b5-02329f1f5567",
            "metadata": {},
            "source": [
                "## Log in to Huggingface\n",
                "\n",
                "Our datasets are shared via HuggingFace Datasets in our [HuggingFace BirdSet repository](https://huggingface.co/datasets/DBD-research-group/birdset_v1). Huggingface is a central hub for sharing and utilizing datasets and models, particularly beneficial for machine learning and data science projects. For accessing private datasets hosted on HuggingFace, you need to be authenticated. Here's how you can log in to HuggingFace:\n",
                "\n",
                "1. **Install HuggingFace CLI**: If you haven't already, you need to install the HuggingFace CLI (Command Line Interface). This tool enables you to interact with HuggingFace services directly from your terminal. You can install it using pip:\n",
                "\n",
                "   ```bash\n",
                "   pip install huggingface_hub\n",
                "   ```\n",
                "\n",
                "2. **Login via CLI**: Once the HuggingFace CLI is installed, you can log in to your HuggingFace account directly from your terminal. This step is essential for accessing private datasets or contributing to the HuggingFace community. Use the following command:\n",
                "\n",
                "   ```bash\n",
                "   huggingface-cli login\n",
                "   ```\n",
                "\n",
                "   After executing this command, you'll be prompted to enter your HuggingFace credentials ([User Access Token](https://huggingface.co/docs/hub/security-tokens)). Once authenticated, your credentials will be saved locally, allowing seamless access to HuggingFace resources."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "89c29ea2",
            "metadata": {},
            "source": [
                "## TLDR;\n",
                "To get started with the default configuration, you can use the following code snippet to set up the BirdSet pipeline to load the [High Sierras](https://zenodo.org/records/7525805) test dataset (10,296 samples) including a train set (5,197 samples) with matching bird classes from [xeno-canto](https://xeno-canto.org/). The total size of the dataset is 6.2GB. The samples will be provided as spectrograms with a resolution of `128x1024` pixels in batches of size `32`, the labels are one-hot encoded for a multilabel classification task. Down below you find further information on how to configure the pipeline to your needs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "9f345d07",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "fda65c8f876f40bdae53b429b7a1ce4e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading builder script:   0%|          | 0.00/19.5k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ca24c6b5898a442097a380bdd579884c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading readme:   0%|          | 0.00/10.8k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c640c98dd10342edb39b9a284f220a87",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading extra modules:   0%|          | 0.00/146k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f8c3d0b14fd54ee0b250445f339aebb8",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading extra modules:   0%|          | 0.00/10.8k [00:00<?, ?B/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "   "
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "07fcb835aa514a7fb5faf1772e5c590d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading data files #1:   0%|          | 0/2 [00:00<?, ?obj/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "7d4384ec5c45431db57e7c470f9b3a98",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading data files #0:   0%|          | 0/2 [00:00<?, ?obj/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2eea2c1d01eb4727b0cc757d4fc37d4d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Downloading data files #2:   0%|          | 0/1 [00:00<?, ?obj/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "ename": "KeyboardInterrupt",
                    "evalue": "",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[3], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m dm \u001b[38;5;241m=\u001b[39m BirdSetDataModule()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# prepare the data (download dataset, ...)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# setup the dataloaders\u001b[39;00m\n\u001b[1;32m      8\u001b[0m dm\u001b[38;5;241m.\u001b[39msetup(stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m/workspace/birdset/datamodule/base_datamodule.py:199\u001b[0m, in \u001b[0;36mBaseDataModuleHF.prepare_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    197\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrepare Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 199\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_preprocess_data(dataset)\n\u001b[1;32m    201\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_splits(dataset)\n",
                        "File \u001b[0;32m/workspace/birdset/datamodule/birdset_datamodule.py:78\u001b[0m, in \u001b[0;36mBirdSetDataModule._load_data\u001b[0;34m(self, decode)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_load_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, decode: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     67\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    Loads the data.\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m        The loaded data.\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/workspace/birdset/datamodule/base_datamodule.py:304\u001b[0m, in \u001b[0;36mBaseDataModuleHF._load_data\u001b[0;34m(self, decode)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;124;03mLoad audio dataset from Hugging Face Datasets.\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \n\u001b[1;32m    300\u001b[0m \u001b[38;5;124;03mReturns HF dataset with audio column casted to Audio feature, containing audio data as numpy array and sampling rate.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    302\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Loading data set.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 304\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dataset, IterableDataset \u001b[38;5;241m|\u001b[39mIterableDatasetDict):\n\u001b[1;32m    311\u001b[0m     logging\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterable datasets not supported yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-xS3fZVNL-py3.10/lib/python3.10/site-packages/datasets/load.py:2153\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\u001b[0m\n\u001b[1;32m   2150\u001b[0m try_from_hf_gcs \u001b[38;5;241m=\u001b[39m path \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _PACKAGED_DATASETS_MODULES\n\u001b[1;32m   2152\u001b[0m \u001b[38;5;66;03m# Download and prepare data\u001b[39;00m\n\u001b[0;32m-> 2153\u001b[0m \u001b[43mbuilder_instance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2154\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2155\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2156\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2157\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtry_from_hf_gcs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtry_from_hf_gcs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2158\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2159\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2160\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2162\u001b[0m \u001b[38;5;66;03m# Build dataset for splits\u001b[39;00m\n\u001b[1;32m   2163\u001b[0m keep_in_memory \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   2164\u001b[0m     keep_in_memory \u001b[38;5;28;01mif\u001b[39;00m keep_in_memory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m is_small_dataset(builder_instance\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size)\n\u001b[1;32m   2165\u001b[0m )\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-xS3fZVNL-py3.10/lib/python3.10/site-packages/datasets/builder.py:954\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[0;34m(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    953\u001b[0m         prepare_split_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_proc\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_proc\n\u001b[0;32m--> 954\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_split_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdownload_and_prepare_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;66;03m# Sync info\u001b[39;00m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mdataset_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(split\u001b[38;5;241m.\u001b[39mnum_bytes \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39msplits\u001b[38;5;241m.\u001b[39mvalues())\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-xS3fZVNL-py3.10/lib/python3.10/site-packages/datasets/builder.py:1717\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_splits_kwargs)\u001b[0m\n\u001b[1;32m   1716\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_download_and_prepare\u001b[39m(\u001b[38;5;28mself\u001b[39m, dl_manager, verification_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mprepare_splits_kwargs):\n\u001b[0;32m-> 1717\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_download_and_prepare\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1718\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1719\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1720\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_duplicate_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBASIC_CHECKS\u001b[49m\n\u001b[1;32m   1721\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mverification_mode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mVerificationMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL_CHECKS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprepare_splits_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-xS3fZVNL-py3.10/lib/python3.10/site-packages/datasets/builder.py:1027\u001b[0m, in \u001b[0;36mDatasetBuilder._download_and_prepare\u001b[0;34m(self, dl_manager, verification_mode, **prepare_split_kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m split_dict \u001b[38;5;241m=\u001b[39m SplitDict(dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_name)\n\u001b[1;32m   1026\u001b[0m split_generators_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_split_generators_kwargs(prepare_split_kwargs)\n\u001b[0;32m-> 1027\u001b[0m split_generators \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_split_generators\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdl_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msplit_generators_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;66;03m# Checksums verification\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verification_mode \u001b[38;5;241m==\u001b[39m VerificationMode\u001b[38;5;241m.\u001b[39mALL_CHECKS \u001b[38;5;129;01mand\u001b[39;00m dl_manager\u001b[38;5;241m.\u001b[39mrecord_checksums:\n",
                        "File \u001b[0;32m~/.cache/huggingface/modules/datasets_modules/datasets/DBD-research-group--BirdSet/fa553675f0fcf4af28e87d691009f0a7fd893f0beade83a17cc78fc847541d19/BirdSet.py:330\u001b[0m, in \u001b[0;36mBirdSet._split_generators\u001b[0;34m(self, dl_manager)\u001b[0m\n\u001b[1;32m    324\u001b[0m     dl_dir \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mdownload({\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: [os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_shard_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m04d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.tar.gz\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, train_files[ds_name] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)],\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdata_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_metadata.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    327\u001b[0m     })\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m train_files\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 330\u001b[0m     dl_dir \u001b[38;5;241m=\u001b[39m \u001b[43mdl_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mds_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_train_shard_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m04d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.tar.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mds_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mds_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_test_shard_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mn\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m04d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.tar.gz\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_files\u001b[49m\u001b[43m[\u001b[49m\u001b[43mds_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta_train\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mds_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_metadata_train.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mds_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_metadata_test.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmeta_test_5s\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mds_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_metadata_test_5s.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m local_audio_archives_paths \u001b[38;5;241m=\u001b[39m dl_manager\u001b[38;5;241m.\u001b[39mextract(dl_dir) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dl_manager\u001b[38;5;241m.\u001b[39mis_streaming \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mXC\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_xc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-xS3fZVNL-py3.10/lib/python3.10/site-packages/datasets/download/download_manager.py:428\u001b[0m, in \u001b[0;36mDownloadManager.download\u001b[0;34m(self, url_or_urls)\u001b[0m\n\u001b[1;32m    425\u001b[0m download_func \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download, download_config\u001b[38;5;241m=\u001b[39mdownload_config)\n\u001b[1;32m    427\u001b[0m start_time \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow()\n\u001b[0;32m--> 428\u001b[0m downloaded_path_or_paths \u001b[38;5;241m=\u001b[39m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl_or_urls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_progress_bar_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDownloading data files\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m duration \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m    437\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownloading took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mduration\u001b[38;5;241m.\u001b[39mtotal_seconds()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-xS3fZVNL-py3.10/lib/python3.10/site-packages/datasets/utils/py_utils.py:475\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[1;32m    470\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[1;32m    471\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    472\u001b[0m             message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.* is experimental and might be subject to breaking changes in the future\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m.$\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    473\u001b[0m             category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m    474\u001b[0m         )\n\u001b[0;32m--> 475\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mparallel_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_single_map_nested\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(data_struct\u001b[38;5;241m.\u001b[39mkeys(), mapped))\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-xS3fZVNL-py3.10/lib/python3.10/site-packages/datasets/utils/experimental.py:40\u001b[0m, in \u001b[0;36mexperimental.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_inner_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     36\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     37\u001b[0m         (\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is experimental and might be subject to breaking changes in the future.\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m     39\u001b[0m     )\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-xS3fZVNL-py3.10/lib/python3.10/site-packages/datasets/parallel/parallel.py:34\u001b[0m, in \u001b[0;36mparallel_map\u001b[0;34m(function, iterable, num_proc, types, disable_tqdm, desc, single_map_nested_func)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m**Experimental.** Apply a function to iterable elements in parallel, where the implementation uses either\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03mmultiprocessing.Pool or joblib for parallelization.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m        element of `iterable`, and `rank` is used for progress bar.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ParallelBackendConfig\u001b[38;5;241m.\u001b[39mbackend_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_map_with_multiprocessing_pool\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_map_nested_func\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _map_with_joblib(function, iterable, num_proc, types, disable_tqdm, desc, single_map_nested_func)\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/gadme-xS3fZVNL-py3.10/lib/python3.10/site-packages/datasets/parallel/parallel.py:65\u001b[0m, in \u001b[0;36m_map_with_multiprocessing_pool\u001b[0;34m(function, iterable, num_proc, types, disable_tqdm, desc, single_map_nested_func)\u001b[0m\n\u001b[1;32m     63\u001b[0m     initargs, initializer \u001b[38;5;241m=\u001b[39m (RLock(),), tqdm\u001b[38;5;241m.\u001b[39mset_lock\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(num_proc, initargs\u001b[38;5;241m=\u001b[39minitargs, initializer\u001b[38;5;241m=\u001b[39minitializer) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 65\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m \u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_map_nested_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_kwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_proc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m processes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     67\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [obj \u001b[38;5;28;01mfor\u001b[39;00m proc_res \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m proc_res]\n",
                        "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;124;03m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;124;03m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapstar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
                        "File \u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_event\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m/usr/lib/python3.10/threading.py:607\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 607\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
                        "File \u001b[0;32m/usr/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
                    ]
                }
            ],
            "source": [
                "from birdset.datamodule.birdset_datamodule import BirdSetDataModule\n",
                "\n",
                "# initiate the data module\n",
                "dm = BirdSetDataModule()\n",
                "# prepare the data (download dataset, ...)\n",
                "dm.prepare_data()\n",
                "# setup the dataloaders\n",
                "dm.setup(stage=\"fit\")\n",
                "# get the dataloaders\n",
                "train_loader = dm.train_dataloader()\n",
                "# get the first batch\n",
                "batch = next(iter(train_loader))\n",
                "# get shape of the batch\n",
                "print(batch[\"input_values\"].shape)\n",
                "print(batch[\"labels\"].shape)\n",
                "batch\n",
                "   "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "5584fa7f",
            "metadata": {},
            "outputs": [
                {
                    "ename": "MisconfigurationException",
                    "evalue": "No supported gpu backend found!",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m min_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      3\u001b[0m max_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[0;32m----> 4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmin_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/birdset-xS3fZVNL-py3.10/lib/python3.10/site-packages/lightning/pytorch/utilities/argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/birdset-xS3fZVNL-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:401\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, accelerator, strategy, devices, num_nodes, precision, logger, callbacks, fast_dev_run, max_epochs, min_epochs, max_steps, min_steps, max_time, limit_train_batches, limit_val_batches, limit_test_batches, limit_predict_batches, overfit_batches, val_check_interval, check_val_every_n_epoch, num_sanity_val_steps, log_every_n_steps, enable_checkpointing, enable_progress_bar, enable_model_summary, accumulate_grad_batches, gradient_clip_val, gradient_clip_algorithm, deterministic, benchmark, inference_mode, use_distributed_sampler, profiler, detect_anomaly, barebones, plugins, sync_batchnorm, reload_dataloaders_every_n_epochs, default_root_dir)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# init connectors\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector \u001b[38;5;241m=\u001b[39m _DataConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 401\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_connector \u001b[38;5;241m=\u001b[39m \u001b[43m_AcceleratorConnector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m    \u001b[49m\u001b[43msync_batchnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msync_batchnorm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbenchmark\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbenchmark\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_distributed_sampler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplugins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector \u001b[38;5;241m=\u001b[39m _LoggerConnector(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callback_connector \u001b[38;5;241m=\u001b[39m _CallbackConnector(\u001b[38;5;28mself\u001b[39m)\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/birdset-xS3fZVNL-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:152\u001b[0m, in \u001b[0;36m_AcceleratorConnector.__init__\u001b[0;34m(self, devices, num_nodes, accelerator, strategy, plugins, precision, sync_batchnorm, benchmark, use_distributed_sampler, deterministic)\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_choose_auto_accelerator()\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_flag \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accelerator_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_choose_gpu_accelerator_backend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_device_config_and_set_final_flags(devices\u001b[38;5;241m=\u001b[39mdevices, num_nodes\u001b[38;5;241m=\u001b[39mnum_nodes)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_parallel_devices_and_init_accelerator()\n",
                        "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/birdset-xS3fZVNL-py3.10/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/accelerator_connector.py:372\u001b[0m, in \u001b[0;36m_AcceleratorConnector._choose_gpu_accelerator_backend\u001b[0;34m()\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m CUDAAccelerator\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 372\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo supported gpu backend found!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                        "\u001b[0;31mMisconfigurationException\u001b[0m: No supported gpu backend found!"
                    ]
                }
            ],
            "source": [
                "from lightning import Trainer\n",
                "min_epochs = 1\n",
                "max_epochs = 5\n",
                "trainer = Trainer(min_epochs=min_epochs, max_epochs=max_epochs, accelerator=\"gpu\", devices=1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "4481caa6",
            "metadata": {},
            "outputs": [],
            "source": [
                "from birdset.modules.base_module import BaseModule\n",
                "model = BaseModule(\n",
                "    len_trainset=dm.len_trainset,\n",
                "    task=dm.task,\n",
                "    batch_size=dm.train_batch_size,\n",
                "    num_epochs=max_epochs)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "e6b4e077",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "BaseModule(\n",
                            "  (loss): BCEWithLogitsLoss()\n",
                            "  (model): EfficientNetClassifier(\n",
                            "    (model): EfficientNet(\n",
                            "      (features): Sequential(\n",
                            "        (0): Conv2dNormActivation(\n",
                            "          (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "          (2): SiLU(inplace=True)\n",
                            "        )\n",
                            "        (1): Sequential(\n",
                            "          (0): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
                            "                (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (2): Conv2dNormActivation(\n",
                            "                (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
                            "          )\n",
                            "          (1): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
                            "                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (2): Conv2dNormActivation(\n",
                            "                (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.008695652173913044, mode=row)\n",
                            "          )\n",
                            "        )\n",
                            "        (2): Sequential(\n",
                            "          (0): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
                            "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.017391304347826087, mode=row)\n",
                            "          )\n",
                            "          (1): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
                            "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.026086956521739136, mode=row)\n",
                            "          )\n",
                            "          (2): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
                            "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.034782608695652174, mode=row)\n",
                            "          )\n",
                            "        )\n",
                            "        (3): Sequential(\n",
                            "          (0): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
                            "                (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.043478260869565216, mode=row)\n",
                            "          )\n",
                            "          (1): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
                            "                (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.05217391304347827, mode=row)\n",
                            "          )\n",
                            "          (2): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
                            "                (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.06086956521739131, mode=row)\n",
                            "          )\n",
                            "        )\n",
                            "        (4): Sequential(\n",
                            "          (0): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
                            "                (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.06956521739130435, mode=row)\n",
                            "          )\n",
                            "          (1): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
                            "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.0782608695652174, mode=row)\n",
                            "          )\n",
                            "          (2): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
                            "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.08695652173913043, mode=row)\n",
                            "          )\n",
                            "          (3): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
                            "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.09565217391304348, mode=row)\n",
                            "          )\n",
                            "        )\n",
                            "        (5): Sequential(\n",
                            "          (0): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
                            "                (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.10434782608695654, mode=row)\n",
                            "          )\n",
                            "          (1): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
                            "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.11304347826086956, mode=row)\n",
                            "          )\n",
                            "          (2): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
                            "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.12173913043478261, mode=row)\n",
                            "          )\n",
                            "          (3): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
                            "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
                            "          )\n",
                            "        )\n",
                            "        (6): Sequential(\n",
                            "          (0): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
                            "                (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.1391304347826087, mode=row)\n",
                            "          )\n",
                            "          (1): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
                            "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.14782608695652175, mode=row)\n",
                            "          )\n",
                            "          (2): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
                            "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.1565217391304348, mode=row)\n",
                            "          )\n",
                            "          (3): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
                            "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.16521739130434784, mode=row)\n",
                            "          )\n",
                            "          (4): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
                            "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.17391304347826086, mode=row)\n",
                            "          )\n",
                            "        )\n",
                            "        (7): Sequential(\n",
                            "          (0): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
                            "                (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
                            "          )\n",
                            "          (1): MBConv(\n",
                            "            (block): Sequential(\n",
                            "              (0): Conv2dNormActivation(\n",
                            "                (0): Conv2d(320, 1920, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (1): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1920, 1920, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1920, bias=False)\n",
                            "                (1): BatchNorm2d(1920, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "                (2): SiLU(inplace=True)\n",
                            "              )\n",
                            "              (2): SqueezeExcitation(\n",
                            "                (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "                (fc1): Conv2d(1920, 80, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (fc2): Conv2d(80, 1920, kernel_size=(1, 1), stride=(1, 1))\n",
                            "                (activation): SiLU(inplace=True)\n",
                            "                (scale_activation): Sigmoid()\n",
                            "              )\n",
                            "              (3): Conv2dNormActivation(\n",
                            "                (0): Conv2d(1920, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "                (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "              )\n",
                            "            )\n",
                            "            (stochastic_depth): StochasticDepth(p=0.19130434782608696, mode=row)\n",
                            "          )\n",
                            "        )\n",
                            "        (8): Conv2dNormActivation(\n",
                            "          (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
                            "          (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
                            "          (2): SiLU(inplace=True)\n",
                            "        )\n",
                            "      )\n",
                            "      (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
                            "      (classifier): Sequential(\n",
                            "        (0): Dropout(p=0.2, inplace=True)\n",
                            "        (1): Linear(in_features=1280, out_features=21, bias=True)\n",
                            "      )\n",
                            "    )\n",
                            "  )\n",
                            "  (train_metric): cmAP()\n",
                            "  (valid_metric): cmAP()\n",
                            "  (test_metric): cmAP()\n",
                            "  (valid_metric_best): MaxMetric()\n",
                            "  (valid_add_metrics): MetricCollection(\n",
                            "    (MultlabelAUROC): MultilabelAUROC(),\n",
                            "    prefix=val/\n",
                            "  )\n",
                            "  (test_add_metrics): MetricCollection(\n",
                            "    (MultlabelAUROC): MultilabelAUROC(),\n",
                            "    prefix=test/\n",
                            "  )\n",
                            "  (test_complete_metrics): MetricCollection(\n",
                            "    (cmAP5): cmAP5(\n",
                            "      (multilabel_ap): MultilabelAveragePrecision()\n",
                            "    )\n",
                            "    (pcmAP): pcmAP(),\n",
                            "    prefix=test/\n",
                            "  )\n",
                            ")"
                        ]
                    },
                    "execution_count": 6,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "93cc4646",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "You are using a CUDA device ('NVIDIA A100 80GB PCIe') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
                        "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
                        "\n",
                        "  | Name                  | Type                   | Params\n",
                        "-----------------------------------------------------------------\n",
                        "0 | loss                  | BCEWithLogitsLoss      | 0     \n",
                        "1 | model                 | EfficientNetClassifier | 6.5 M \n",
                        "2 | train_metric          | cmAP                   | 0     \n",
                        "3 | valid_metric          | cmAP                   | 0     \n",
                        "4 | test_metric           | cmAP                   | 0     \n",
                        "5 | valid_metric_best     | MaxMetric              | 0     \n",
                        "6 | valid_add_metrics     | MetricCollection       | 0     \n",
                        "7 | test_add_metrics      | MetricCollection       | 0     \n",
                        "8 | test_complete_metrics | MetricCollection       | 0     \n",
                        "-----------------------------------------------------------------\n",
                        "6.5 M     Trainable params\n",
                        "0         Non-trainable params\n",
                        "6.5 M     Total params\n",
                        "26.158    Total estimated model params size (MB)\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e2b6b96b34b04e94a5057fb5cb10637e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "56bb041a8f6b46dabc9ab4f74ff48250",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Training: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "96dad4d8725c484885bcefddde553485",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "51c406c1423e4d119392b476799b8e16",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "19d5b5ed3069456ca23df923dd5f758b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8d7a64f6169349e3a7385af1f99cc84e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "25ddab332c3e45469f95cf4b12b37b65",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
                    ]
                }
            ],
            "source": [
                "trainer.fit(model, dm)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "73be30bd-772f-407f-9925-ef247dbc8219",
            "metadata": {},
            "source": [
                "## Configuration of BirdSet Data Pipeline\n",
                "\n",
                "The BirdSet Data Pipeline offers a robust and flexible configuration system, primarily designed to streamline the process of setting up your data processing environment. While this notebook presents hardcoded configurations for simplicity, it's important to note that these settings can be dynamically managed using advanced configuration tools like Hydra. Hydra is a powerful utility that enables flexible and scalable configuration management, allowing you to adapt the pipeline settings to various environments or use cases seamlessly. For an in-depth understanding of Hydra, consider visiting [Hydra's official documentation](https://hydra.cc/docs/intro).\n",
                "\n",
                "Tipp! Detailed information is provided in the docstrings of the classes and functions. You can access them by hovering over the class or function name in your IDE or by opening the source file in a text editor."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7ad76228",
            "metadata": {},
            "source": [
                "### BirdSetDataModule\n",
                "The `BirdSetDataModule` is a [PyTorch Lightning DataModule](https://lightning.ai/docs/pytorch/stable/data/datamodule.html#lightningdatamodule) that encapsulates the entire data pipeline. It inherits from `BaseDataModuleHF` which is a base class for all DataModules that use [HuggingFace datasets libary](https://huggingface.co/docs/datasets/index).\n",
                "\n",
                "To initialize the `BirdSetDataModule`, you need to provide the following parameters:\n",
                "\n",
                "```python\n",
                "from src.datamodule.birdset_datamodule import BirdSetDataModule\n",
                "\n",
                "data_module = BirdSetDataModule(\n",
                "    dataset=dataset_config, #dataset (DatasetConfig): The configuration for the dataset.\n",
                "    loaders=loaders_config, #loaders (LoadersConfig): The configuration for the loaders.\n",
                "    transforms=transforms, #transforms (BirdSetTransformsWrapper): The transforms to be applied to the data.\n",
                "    mapper=mapper #mapper (XCEventMapping): The mapping for the events.\n",
                ")\n",
                "```\n",
                "\n",
                "We will now walk through each of these parameters to understand their functionality and configuration.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5158f248-890f-47d0-8b16-68758a314685",
            "metadata": {},
            "source": [
                "### 1. Dataset Configuration\n",
                "\n",
                "Configuring the dataset is the first step in configuring the BirdSet data pipeline, here you specify which dataset you want to load, how many classes it has, and how the data is split into train, validation, and test sets. The `DatasetConfig` class is used to configure the dataset."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "33cca9fe-2ac0-4418-93d1-e8ad5fd37786",
            "metadata": {},
            "outputs": [],
            "source": [
                "from birdset.datamodule.base_datamodule import DatasetConfig\n",
                "\n",
                "dataset_config = DatasetConfig(\n",
                "    data_dir='../../data_birdset',\n",
                "    dataset_name='HSN',\n",
                "    hf_path='DBD-research-group/BirdSet',\n",
                "    hf_name='HSN',\n",
                "    n_classes=21,\n",
                "    n_workers=1,\n",
                "    val_split=0.2,\n",
                "    task=\"multilabel\",\n",
                "    subset=None,\n",
                "    sampling_rate=32000,\n",
                "    class_weights_sampler=None,\n",
                "    classlimit=500,\n",
                "    eventlimit=5,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e8ea4694-e2e8-4b71-a2ad-6b004850f7e1",
            "metadata": {
                "tags": []
            },
            "source": [
                "Here's a brief overview of the parameters used in the `DatasetConfig` class:\n",
                "\n",
                "- `data_dir`: Specifies the directory where the dataset files are stored. **Important**: The dataset uses a lot of disk space, so make sure you have enough storage available.\n",
                "- `dataset_name`: The name assigned to the dataset.\n",
                "- `hf_path`: The path to the dataset stored on HuggingFace.\n",
                "- `hf_name`: The name of the dataset on HuggingFace.\n",
                "- `seed`: A seed value for ensuring reproducibility across runs.\n",
                "- `n_classes`: The total number of distinct classes in the dataset.\n",
                "- `n_workers`: The number of worker processes used for data loading.\n",
                "- `val_split`: The proportion of the dataset reserved for validation.\n",
                "- `task`: Defines the type of task (e.g., 'multilabel' or 'multiclass').\n",
                "- `sampling_rate`: The sampling rate for audio data processing.\n",
                "- `class_weights_sampler`: Indicates whether to use class weights in the sampler for handling imbalanced datasets.\n",
                "- `class_limit`: The maximum number of samples per class.\n",
                "- `eventlimit`: Defines the maximum number of audio events processed per audio file, capping the quantity to ensure balance across files."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fdc2a0b4-c98c-4e95-9b51-3e7f17d038eb",
            "metadata": {},
            "source": [
                "#### Important Note:\n",
                "- The `class_weights_loss` parameter is currently deprecated and only implemented for focal loss. It's recommended to utilize the `class_weights_sampler` instead, as it has shown to yield favorable results, particularly as evidenced by the winner of the [BirdCLEF 2023](https://www.kaggle.com/competitions/birdclef-2023) challenge."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5f58a9d4-aabd-43b7-b6f6-e7acbb4cefeb",
            "metadata": {},
            "source": [
                "Selecting appropriate values for these parameters is crucial, as they directly influence the efficiency of the training process and the overall performance of the model."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5734f65a-8fb3-4468-8fa2-7bccff9f8097",
            "metadata": {},
            "source": [
                "### 2. Dataloader Configuration\n",
                "\n",
                "Once the dataset is configured, the next crucial step is setting up the data loaders. Data loaders are pivotal in efficiently feeding data into the model during both the training and testing phases. They manage the data flow, ensuring that the model is supplied with a consistent stream of data batches. In this section, we'll use the `LoaderConfig` and `LoadersConfig` classes to define different configurations for the training and testing data loaders."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "5a49150e-4ce1-4ed4-abc7-9d376eb9c3b4",
            "metadata": {},
            "outputs": [],
            "source": [
                "from birdset.datamodule.base_datamodule import LoaderConfig, LoadersConfig\n",
                "# Configuration for the training data loader\n",
                "train_loader_config = LoaderConfig(\n",
                "    batch_size=32,\n",
                "    shuffle=True,\n",
                "    num_workers=8,\n",
                "    pin_memory=False,\n",
                "    drop_last=True,\n",
                "    persistent_workers=False,\n",
                "    #prefetch_factor=None,\n",
                ")\n",
                "\n",
                "# Configuration for the testing data loader\n",
                "test_loader_config = LoaderConfig(\n",
                "    batch_size=32,\n",
                "    shuffle=False,\n",
                "    num_workers=8,\n",
                "    pin_memory=False,\n",
                "    drop_last=False,\n",
                "    persistent_workers=False,\n",
                "    #prefetch_factor=None,\n",
                ")\n",
                "\n",
                "# Aggregating the loader configurations\n",
                "loaders_config = LoadersConfig(\n",
                "    train=train_loader_config,\n",
                "    valid=test_loader_config,\n",
                "    test=test_loader_config,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "3ea42652-6857-4d0e-be29-8f50928aad0b",
            "metadata": {},
            "source": [
                "Here's a brief overview of the parameters used in the `LoaderConfig` class:\n",
                "\n",
                "- `batch_size`: Specifies the number of samples contained in each batch. This is a crucial parameter as it impacts memory utilization and model performance.\n",
                "- `shuffle`: Determines whether the data is shuffled at the beginning of each epoch. Shuffling is typically used for training data to ensure model robustness and prevent overfitting.\n",
                "- `num_workers`: Sets the number of subprocesses to be used for data loading. More workers can speed up the data loading process but also increase memory consumption.\n",
                "- `pin_memory`: When set to `True`, enables the DataLoader to copy Tensors into CUDA pinned memory before returning them. This can lead to faster data transfer to CUDA-enabled GPUs.\n",
                "- `drop_last`: Determines whether to drop the last incomplete batch. Setting this to `True` is useful when the total size of the dataset is not divisible by the batch size.\n",
                "- `persistent_workers`: Indicates whether the data loader should keep the workers alive for the next epoch. This can improve performance at the cost of memory.\n",
                "- `prefetch_factor`: Defines the number of samples loaded in advance by each worker. This parameter is commented out here and can be adjusted based on specific requirements.\n",
                "\n",
                "Proper configuration of the data loaders is essential as it directly influences the efficiency of the training process, hardware resource utilization, and ultimately, the performance of the model."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "09a2390d-937a-46c8-8829-94ff3eca2b28",
            "metadata": {},
            "source": [
                "### 3. Configuration of TransformationsWrapper\n",
                "\n",
                "Transformations play a critical role in the data preparation process within the BirdSet data pipeline. These operations, applied before the data is fed into the model, encompass a range of augmentation techniques designed to regularize the model and prevent overfitting. Properly configured transformations not only enhance the diversity and quality of the training data but also help the model generalize better to new, unseen data.\n",
                "\n",
                "In the BirdSet framework, transformations are meticulously orchestrated through the `BirdSetTransformsWrapper` class. This wrapper acts as a comprehensive interface for defining and applying various transformations and augmentations to the data. It ensures that the data is consistently and effectively transformed, aligning with the specific requirements of the model and the inherent characteristics of the dataset.\n",
                "\n",
                "By configuring the `transforms_wrapper` using the `BirdSetTransformsWrapper` class, you gain precise control over how the data is manipulated during the preprocessing phase.\n",
                "\n",
                "To initialize the `BirdSetTransformsWrapper`, you need to provide the following parameters:\n",
                "\n",
                "```python\n",
                "from src.datamodule.components.transforms import BirdSetTransformsWrapper\n",
                "\n",
                "transforms = BirdSetTransformsWrapper(\n",
                "    task: Literal['multiclass', 'multilabel'] = \"multilabel\",\n",
                "    sampling_rate: int = 32000,\n",
                "    model_type: Literal['vision', 'waveform'] = \"waveform\",\n",
                "    spectrogram_augmentations: DictConfig = DictConfig({}),\n",
                "    waveform_augmentations: DictConfig = DictConfig({}),\n",
                "    decoding: EventDecoding | None = None,\n",
                "    feature_extractor: DefaultFeatureExtractor = DefaultFeatureExtractor(),\n",
                "    max_length: int = 5,\n",
                "    nocall_sampler: DictConfig = DictConfig({}),\n",
                "    preprocessing: PreprocessingConfig = PreprocessingConfig()\n",
                ")\n",
                "```\n",
                "\n",
                "We will go through each of these parameters to understand their functionality and configuration."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "239b8432",
            "metadata": {},
            "source": [
                "#### 3.1 Dataset and Model specific parameters\n",
                "The following parameters ensure that the transformations are tailored to the specific requirements of the dataset and the model:\n",
                "\n",
                "- `task`: Defines the type of task (e.g., 'multilabel' or 'multiclass').\n",
                "- `sampling_rate`: The sampling rate for audio data processing.\n",
                "- `model_type`: Specifies the type of model (e.g., 'vision' or 'waveform'). In case of a vison model, the input data is expected to be a spectrogram, while for a waveform model, the input data is the raw audio waveform.\n",
                "- max_length: The maximum length of the audio files in seconds."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a16af9b0-b4da-47a3-a551-433009c4739d",
            "metadata": {},
            "source": [
                "#### 3.2 Augmentations\n",
                "\n",
                "Augmentations are powerful techniques applied to the data to introduce diversity and variability. They are particularly useful in audio and signal processing to enhance the robustness of models against variations in input data. In the BirdSet framework, you can configure waveform and spectrogram augmentations as follows:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "306dfe3d-b6a1-41e9-ab21-ac551e501dd9",
            "metadata": {
                "tags": []
            },
            "source": [
                "**Waveform Augmentations**\n",
                "\n",
                "These augmentations are applied directly to the audio waveform. In BirdSet, you can use any waveform augmentation technique as long as it can be composed by the [torch-audiomentations Compose function](https://github.com/asteroid-team/torch-audiomentations/blob/main/torch_audiomentations/core/composition.py). You can add waveform augmentations as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "263b67d3-0a2f-4ccf-b8eb-d55af0236ac9",
            "metadata": {},
            "outputs": [],
            "source": [
                "from torch_audiomentations import AddColoredNoise, PitchShift\n",
                "waveform_augmentation = {\n",
                "    \"colored_noise\": AddColoredNoise(p=0.2, min_snr_in_db=3.0, max_snr_in_db=30.0, min_f_decay=-2.0, max_f_decay=2.0),\n",
                "    \"pitch_shift\": PitchShift(p=0.2, sample_rate=32000, min_transpose_semitones=-4.0, max_transpose_semitones=4.0),\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "47c94eee-4cd7-49eb-b277-1902b48ced9e",
            "metadata": {},
            "source": [
                "In this example:\n",
                "- `colored_noise`: Adds colored noise to the audio signal to simulate various real-world noise conditions.\n",
                "- `pitch_shift`: Alters the pitch of the audio signal, which is useful for simulating different tonal variations."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "daf77953-a58d-4e81-8e50-2d15be2ca0bf",
            "metadata": {},
            "source": [
                "**Spectrogram Augmentations**\n",
                "\n",
                "These augmentations are applied to the spectrogram representation of the audio. In BirdSet, you can use any spectrogram augmentation technique as long as it can be composed by the [torchvision Compose function](https://pytorch.org/vision/stable/generated/torchvision.transforms.Compose.html). You can add spectrogram augmentations as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "58e9af4b-879b-4095-92da-99a5e0992c9e",
            "metadata": {},
            "outputs": [],
            "source": [
                "from torchvision.transforms import RandomApply\n",
                "from torchaudio.transforms import TimeMasking, FrequencyMasking\n",
                "spectrogram_augmentations = {\n",
                "    \"time_masking\": RandomApply([TimeMasking(time_mask_param=100, iid_masks=True)], p=0.3),\n",
                "    \"frequency_masking\": RandomApply([FrequencyMasking(freq_mask_param=100, iid_masks=True)], p=0.5)\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e8aca7d4-609d-4519-8675-ee7a35fa52c2",
            "metadata": {},
            "source": [
                "In this example:\n",
                "- `time_masking`: Randomly masks a sequence of consecutive time steps in the spectrogram, helping the model become invariant to small temporal shifts.\n",
                "- `frequency_masking`: Randomly masks a sequence of consecutive frequency channels, encouraging the model to be robust against frequency variations."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "04268897-f6f4-4488-9d85-12cf23c15baf",
            "metadata": {},
            "source": [
                "Configuring the augmentations correctly is crucial as they directly influence the model's ability to learn from a diverse set of data representations, ultimately leading to better generalization and performance."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "08ee00cb-31db-4f66-883f-623791389e06",
            "metadata": {},
            "source": [
                "#### 3.3 Decoding\n",
                "\n",
                "Decoding is a process, that converts the (compressed) data into a format that can be directly used by the model. In the BirdSet framework, we use the `EventDecoding` class by default. It is designed for preprocessing audio files in the context of event detection tasks. Its primary function is to ensure that each audio segment fed into the model is not only in the correct format, but also conditioned to improve the model's ability to identify and understand different audio events. Decoding is configured as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "b7e2b022-ae03-4940-99de-3bf4823ce506",
            "metadata": {},
            "outputs": [],
            "source": [
                "from birdset.datamodule.components import EventDecoding\n",
                "decoding = EventDecoding(\n",
                "    min_len=1.0,\n",
                "    max_len=5.0,\n",
                "    sampling_rate=32000,\n",
                "    extension_time=8,\n",
                "    extracted_interval=5,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8ad60adc-3a7e-4506-9c7e-529074359b9f",
            "metadata": {},
            "source": [
                "Key Parameters:\n",
                "- `_target_`: Specifies the EventDecoding component to be used in the data processing pipeline.\n",
                "- `min_len` and `max_len`: Determine the minimum and maximum duration (in seconds) of the audio segments after decoding. These constraints ensure that each processed audio segment is of a suitable length for the model.\n",
                "- `sampling_rate`: Defines the sampling rate to which the audio should be resampled. This standardizes the input data's sampling rate, making it consistent for model processing.\n",
                "- `extension_time`: Refers to the time (in seconds) by which the duration of an audio event is extended. This parameter is crucial for ensuring that shorter audio events are sufficiently long for the model to process effectively.\n",
                "- `extracted_interval`: Denotes the fixed duration (in seconds) of the audio segment that is randomly extracted from the extended audio event."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1f6723e8-1b8c-4dcd-b55d-0e934f6f704f",
            "metadata": {},
            "source": [
                "Decoding is performed on the fly, ensuring that the data fed into the model is always in the correct format, even when the source data comes in various encoded forms."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "af655211-4a1a-4015-b40f-a6f6fbf2647c",
            "metadata": {},
            "source": [
                "#### 3.4 Feature Extraction\n",
                "\n",
                "Feature extraction is a pivotal step in transforming raw data into a structured format that is suitable for model training. The `DefaultFeatureExtractor` in BirdSet is tailored for processing waveform data, providing a range of functionalities to prepare the data for model consumption."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "bbf56c70-dfc1-4bd4-8b91-a0e40ac06380",
            "metadata": {},
            "outputs": [],
            "source": [
                "from birdset.datamodule.components import DefaultFeatureExtractor\n",
                "feature_extractor = DefaultFeatureExtractor(\n",
                "    feature_size=1,\n",
                "    sampling_rate=32000,\n",
                "    padding_value=0.0,\n",
                "    return_attention_mask=False,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1f84eaf7-0d06-4a5d-91d1-55ede47349f5",
            "metadata": {},
            "source": [
                "Key Parameters:\n",
                "- `feature_size`: Determines the size of the extracted features.\n",
                "- `sampling_rate`: The sampling rate at which the audio data should be processed.\n",
                "- `padding_value`: The value used for padding shorter sequences to a consistent length.\n",
                "- `return_attention_mask`: Indicates whether an attention mask should be returned along with the processed features."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d6ae4db7-fa6a-4768-a00a-1e588d0534ac",
            "metadata": {},
            "source": [
                "This component is crucial for ensuring that the input data to the model is in a consistent and processable format, catering to models that require structured input in the form of PyTorch tensors."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "98891b2a",
            "metadata": {},
            "source": [
                "#### 3.5 No-call Sampler\n",
                "You can use the `NoCallMixer` to add no-call samples to the dataset. This is particularly useful for training models to recognize the absence of bird calls. The `NoCallMixer` is configured as follows:\n",
                "```python\n",
                "from src.datamodule.components.no_call_sampler import NoCallSampler\n",
                "\n",
                "nocall_sampler = NoCallMixer(\n",
                "    directory: str = \"path/to/no_call_samples\",\n",
                "    p: float = 0.075,\n",
                "    sampling_rate: int = 32000,\n",
                "    length: int = 5,\n",
                "    n_classes: int = 21,\n",
                ")\n",
                "```\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "2300978e",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Since this would require to have the dataset downloaded (see `download_background_noise.ipynb`, we will not use this for now\n",
                "nocall_sampler = None"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e75a91ff-07b7-48f2-a115-7a15de770c52",
            "metadata": {},
            "source": [
                "#### 3.6 Configuration of Data Preprocessing\n",
                "\n",
                "Data preprocessing is a fundamental step in the BirdSet data pipeline, ensuring that the raw data is adequately conditioned and transformed, making it suitable for model consumption. The `PreprocessingConfig` class allows for a detailed specification of various preprocessing parameters, each carefully selected to meet the unique demands of your dataset and model. Here's how you can configure the data preprocessing in the BirdSet pipeline:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "235ed383-b28f-4575-9a8b-02fff555e812",
            "metadata": {},
            "outputs": [],
            "source": [
                "from torchaudio.transforms import Spectrogram\n",
                "from birdset.datamodule.components.resize import Resizer\n",
                "from birdset.datamodule.components.augmentations import PowerToDB\n",
                "from birdset.datamodule.components.transforms import PreprocessingConfig\n",
                "\n",
                "# Creating the preprocessing configuration\n",
                "preprocessing = PreprocessingConfig(\n",
                "        spectrogram_conversion= Spectrogram(\n",
                "            n_fft=1024,\n",
                "            hop_length=320,\n",
                "            power=2.0,\n",
                "        ),\n",
                "        resizer=Resizer(\n",
                "            db_scale=True,\n",
                "            target_height=None,\n",
                "            target_width=1024,\n",
                "        ),\n",
                "        dbscale_conversion=PowerToDB(),\n",
                "        normalize_spectrogram=True,\n",
                "        normalize_waveform=None,\n",
                "        mean=4.268, # calculated on AudioSet\n",
                "        std=4.569 # calculated on AudioSet\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0eff94aa-3191-41e8-a2ec-4393e8418c94",
            "metadata": {},
            "source": [
                "Here's a brief overview of the parameters used in the `PreprocessingConfig` class:\n",
                "\n",
                "- `spectrogram_conversion`: This is an instance of the Spectrogram class from torchaudio.transforms. It is used to convert the audio waveform to a spectrogram. The parameters n_fft, hop_length, and power are used to configure the spectrogram conversion.\n",
                "\n",
                "    - `n_fft`: Th` size of the FFT, which will also determine the size of the window used for the STFT. It is set to 1024.\n",
                "    - `hop_length`: The number of samples between successive frames in the STFT. It is set to 320.\n",
                "    - `power`: The exponent for the magnitude spectrogram, e.g., 1 for energy, 2 for power, etc. It is set to 2.0.\n",
                "    - `resizer`: This is an instance of the Resizer class from src.datamodule.components.resize. It is used to resize the spectrogram. The parameters db_scale and target_width are used to configure the resizing.\n",
                "\n",
                "- `db_scale`: If set to True, the spectrogram is converted to dB scale. It is set to True.\n",
                "- `target_height`: The target height for the resized spectrogram. It is not set in this case.\n",
                "- target_width: The target width for the resized spectrogram. It is set to 1024.\n",
                "- `dbscale_conversion`: This is an instance of the PowerToDB class from src.datamodule.components.augmentations. It is used to convert the spectrogram to a dB scale.\n",
                "\n",
                "- `normalize_spectrogram`: If set to True, the spectrogram is normalized. It is set to True.\n",
                "\n",
                "- `normalize_waveform`: If set to a value, the audio waveform is normalized. It is not set in this case.\n",
                "\n",
                "- ``mean``: The mean value used for normalization. It is set to 4.268, which is calculated on AudioSet.\n",
                "\n",
                "- `std`: The standard deviation used for normalization. It is set to 4.569, which is calculated on AudioSet.\n",
                "\n",
                "\n",
                "By accurately configuring these preprocessing parameters, you ensure that the input data to the model is standardized and optimized for the learning process, which is essential for achieving high performance."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d993142c-54a2-43a0-9e4e-b977571b03fd",
            "metadata": {},
            "source": [
                "#### 3.7 Initiating the BirdSetTransformsWrapper\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "267876cf",
            "metadata": {},
            "outputs": [],
            "source": [
                "from birdset.datamodule.components.transforms import BirdSetTransformsWrapper\n",
                "transforms = BirdSetTransformsWrapper(\n",
                "    task=\"multilabel\",\n",
                "    sampling_rate=32000,\n",
                "    model_type=\"vision\",\n",
                "    spectrogram_augmentations=spectrogram_augmentations,\n",
                "    waveform_augmentations=waveform_augmentation,\n",
                "    decoding=decoding,\n",
                "    feature_extractor=feature_extractor,\n",
                "    max_length=5,\n",
                "    nocall_sampler=nocall_sampler,\n",
                "    preprocessing=preprocessing,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fb170e58-deed-4b52-ba18-160681b5dba0",
            "metadata": {},
            "source": [
                "### 4. Configuration of Event Mappings\n",
                "\n",
                "Event mapping plays a pivotal role in the data pipeline, serving as the bridge between raw dataset events and the structured input required by the model. This process ensures that each event in the dataset is accurately represented and can be effectively utilized during model training. By default, we use [bambird](https://www.sciencedirect.com/science/article/pii/S1574954122004022?casa_token=HEbcdB5MyRMAAAAA:saYbr1WNlJTs-kAZOtzMrNt5r1sN_69E7bMjfCJu2A4zlLLFoIt-5-Cht2Wryg59851H_PWgfHzw) for event mapping, which is implemented in the `XCEventMapping` class. Within the BirdSet framework, event mappings are configured as follows:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "d4f30431-6972-4536-b323-88b7378e47c7",
            "metadata": {},
            "outputs": [],
            "source": [
                "from birdset.datamodule.components import XCEventMapping\n",
                "# Instantiate the event mapper\n",
                "mapper = XCEventMapping(\n",
                "            biggest_cluster=True,\n",
                "            no_call=False,\n",
                "        )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "bd405878-31de-4fbc-9729-20410747c89d",
            "metadata": {},
            "source": [
                "Key Parameters in Event Mapping:\n",
                "- `biggest_cluster`: If set to `True`, the mapper focuses on the biggest cluster of events, which can be particularly useful for datasets with imbalanced event distributions.\n",
                "- ``: Specifies the maximum number of events to consider. This can be used to limit the scope of the mapping, although it's usually already managed by the `DatasetConfig`.\n",
                "- `no_call`: Indicates whether 'no-call' events should be included. In this configuration, it's set to `False` as the no-call samples are handled separately by the `nocall_sampler`."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fedc44f5-852c-4231-bafd-4757ee27841f",
            "metadata": {},
            "source": [
                "Properly configuring the event mappings is essential for ensuring that the model receives accurately structured and meaningful data, which is a cornerstone for effective model training and robust performance."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "704cfdb6-d25c-46b7-a1ee-47d4b834e01f",
            "metadata": {},
            "source": [
                "## Creating the BirdSet Datamodule\n",
                "\n",
                "The BirdSet Datamodule plays a central role in the BirdSet data pipeline, offering streamlined handling and preprocessing of BirdSet datasets to ensure they are primed for model training. Let's delve into the setup process:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "60180aa6-285c-4879-abca-e88b29578897",
            "metadata": {},
            "source": [
                "### Imports\n",
                "First, we import the necessary modules. `BirdSetDataModule` is responsible for managing the BirdSet datasets, while the `logging` module is used for logging information during the data processing steps."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "0c76242c-928d-4404-922d-30c462681bb0",
            "metadata": {},
            "outputs": [],
            "source": [
                "import logging \n",
                "import os\n",
                "\n",
                "from birdset.datamodule.birdset_datamodule import BirdSetDataModule"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "29444ab9-1b1c-4ea2-b85c-c55b280f2c16",
            "metadata": {},
            "source": [
                "### Creating Cache Directory\n",
                "The cache directory is a dedicated space for storing processed data. Utilizing a cache directory can significantly expedite subsequent data loading operations by avoiding redundant data processing. Here's how to create and manage a cache directory effectively:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "8c8b7b7a-2c44-40d1-a7db-1355d2aefe82",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Log the absolute path of the dataset\n",
                "logging.info(f\"Dataset path: <{os.path.abspath(dataset_config.data_dir)}>\")\n",
                "\n",
                "# Create the dataset directory if it does not exist\n",
                "os.makedirs(dataset_config.data_dir, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "82895c4e-93ac-4590-aeb0-b0acb1f9909b",
            "metadata": {},
            "source": [
                "This approach ensures:\n",
                "- Organized data management: By maintaining a structured directory for your datasets, you facilitate easier access and management of your data assets.\n",
                "- Efficient data loading: By caching processed data, subsequent loads are much faster, which is particularly beneficial when working with large datasets.\n",
                "\n",
                "By carefully setting up the BirdSet Datamodule and managing your cache directory, you enhance the efficiency and reliability of your data pipeline, ensuring that your datasets are always ready for model training."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d764504c-f167-40b4-9297-6ca1184c5668",
            "metadata": {},
            "source": [
                "### Datamodule Initialization\n",
                "\n",
                "The `BirdSetDataModule` class plays a pivotal role in orchestrating the data pipeline. It consolidates the dataset configuration, data loaders, transformations, and event mappings into a cohesive structure, ensuring a clean and manageable workflow. Here's how the BirdSetDataModule is initialized:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "d0586ee6-9cad-4270-acb9-931cf046b6ab",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the BirdSetDataModule\n",
                "datamodule = BirdSetDataModule(\n",
                "        dataset=dataset_config,\n",
                "        loaders=loaders_config,\n",
                "        transforms=transforms,\n",
                "        mapper=mapper,\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cb0982ec-199c-43bc-a2e6-8732f2356cc9",
            "metadata": {},
            "source": [
                "Here's a brief overview of the parameters used in the `BirdSetDataModule` class:\n",
                "- `dataset`: The configuration settings for the dataset. It defines how the data is structured and managed.\n",
                "- `loaders`: Configuration settings for the data loaders, determining how data is batched and fed into the model.\n",
                "- `transforms`: The set of transformations and augmentations applied to the data, ensuring that it's properly conditioned for the model.\n",
                "- `mapper`: The event mapping configuration, essential for translating raw dataset events into a structured format that the model can interpret."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "88ab439e-2ee1-471f-9e38-15dfbc12cdfc",
            "metadata": {},
            "source": [
                "### Data Preparation\n",
                "\n",
                "The data preparation stage is where the actual data processing takes place. This stage is critical in ensuring that the data is correctly preprocessed, structured, and ready for model training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "ee400c19-41a3-4a5e-9011-509bdd319e7b",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "25ed54c457b9459fadb74493ed3d92ed",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/5197 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "329496e1a4724b6487a39ddb5017574b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/37176 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Processing labels: 100%|| 21/21 [00:01<00:00, 11.28it/s]\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a86e43fb85444d11bb716594e9fc07ff",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/17348 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "56dbe5d77a9c4c5e8c9be8c7c0a76595",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Map:   0%|          | 0/12000 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "510f1066cf1e4fdc9bbd2ad8f26bca5b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Saving the dataset (0/1 shards):   0%|          | 0/13878 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d84626e477a2411a84f99d21b5a8f4ea",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Saving the dataset (0/1 shards):   0%|          | 0/3470 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "8156322a98c544ea9ccedeb04814be28",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Saving the dataset (0/1 shards):   0%|          | 0/12000 [00:00<?, ? examples/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Prepare the data for training\n",
                "datamodule.prepare_data()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "eb9cf461-1fb8-4bb4-8db3-f7b4b4830036",
            "metadata": {},
            "source": [
                "The `prepare_data()` method encompasses various steps, including downloading the data (if not already locally available), applying the preprocessing steps defined in the transformations, and organizing the data into a format that is compatible with the model. It's a method that encapsulates the entire data preparation workflow, ensuring that the data is optimally prepared for the training process.\n",
                "\n",
                "This methodical approach to data preparation and modularization of the data pipeline components in the BirdSet framework contributes significantly to the efficiency, maintainability, and robustness of the machine learning lifecycle.\n",
                "\n",
                "**Hint**: If you recive an error concerning a not existing huggingface dataset, please make sure you are logged in to HuggingFace (see [Log in to Huggingface](#log-in-to-huggingface))."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "932e3987-0f9a-4452-8b82-54c0ea96180e",
            "metadata": {},
            "source": [
                "### Datamodule Setup for Training Phase\n",
                "\n",
                "Setting up the datamodule for the training phase is a crucial step in the BirdSet data pipeline. This setup involves initializing the training and validation dataloaders, which play a vital role in supplying the model with data during the training process. The setup is performed using the `setup(stage=\"fit\")` method:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "id": "a252adb3-539e-434c-adcb-2ec2c1f7c996",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup the datamodule for the training phase\n",
                "datamodule.setup(stage=\"fit\")\n",
                "\n",
                "# Retrieve the training and validation dataloaders\n",
                "train_loader = datamodule.train_dataloader()\n",
                "validation_loader = datamodule.val_dataloader()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "id": "2048c240-bac0-465e-836f-1d9718c3a1ce",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(dict_keys(['input_values', 'labels']),\n",
                            " torch.Size([32, 1, 128, 1024]),\n",
                            " torch.Size([32, 21]))"
                        ]
                    },
                    "execution_count": 18,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# Fetch a sample batch from the training dataloader\n",
                "for batch in train_loader:\n",
                "    break\n",
                "\n",
                "# Inspect the keys and shapes of the data in the batch\n",
                "batch.keys(), batch[\"input_values\"].shape, batch[\"labels\"].shape"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "00066181-de6f-4980-90dc-458d6b92f27d",
            "metadata": {},
            "source": [
                "This code snippet demonstrates:\n",
                "- The initialization of the training phase.\n",
                "- The retrieval of training and validation dataloaders.\n",
                "- Fetching and inspecting a sample batch from the training dataloader.\n",
                "- The shapes of `input_values` and `labels` indicate the batch size, number of channels (if applicable), and dimensions of the input data and labels, respectively."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ed731d9c-7aea-49ac-9df9-4fc61774abbc",
            "metadata": {},
            "source": [
                "### Datamodule Setup for Test Phase\n",
                "\n",
                "Similarly, the datamodule is set up for the test phase to ensure that the model can be effectively evaluated using the test data:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "id": "5db95322-ca2b-4f8f-b419-40529d7c92b5",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup the datamodule for the test phase\n",
                "datamodule.setup(stage=\"test\")\n",
                "\n",
                "# Retrieve the test dataloader\n",
                "test_loader = datamodule.test_dataloader()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7d5ed904-f95b-4bad-a03b-531de0a67dc7",
            "metadata": {},
            "source": [
                "The `setup(stage=\"test\")` method prepares the datamodule specifically for the test phase, and `test_dataloader()` retrieves the test dataloader, which is instrumental for batching and loading the test data efficiently during the model evaluation process.\n",
                "\n",
                "By methodically setting up the datamodule for both training and test phases, you ensure that the model has access to well-prepared data, which is essential for accurate training, validation, and testing."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2567af44-494a-4547-b57b-9b487e57a520",
            "metadata": {},
            "source": [
                "### Usage in TensorFlow\n",
                "\n",
                "Utilizing the BirdSet datamodule in a TensorFlow environment involves integrating the prepared dataloaders with TensorFlow's training and evaluation workflows. This integration ensures that the data is fed into TensorFlow models efficiently and in a format that TensorFlow can process. Here's how you can set up the BirdSet datamodule for TensorFlow compatibility:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "id": "ce1c99c0-201a-4cae-9e9e-d4c6f9512fed",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup the datamodule for the training phase\n",
                "datamodule.setup(stage=\"fit\")\n",
                "\n",
                "# Retrieve the training and validation datasets\n",
                "train_loader = datamodule.train_dataset\n",
                "validation_loader = datamodule.val_dataset\n",
                "\n",
                "# Setup the datamodule for the test phase\n",
                "datamodule.setup(stage=\"test\")\n",
                "\n",
                "# Retrieve the test dataset\n",
                "test_loader = datamodule.test_dataset"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d8bda355-34f2-42b2-b57a-b6112f48f49c",
            "metadata": {},
            "source": [
                "#### Key Considerations:\n",
                "- `train_dataset`, `validation_dataset`, and `test_dataset` are the datasets prepared by the BirdSet datamodule, ready to be used in TensorFlow's training and evaluation routines.\n",
                "- It's important to ensure that these datasets are in a format compatible with TensorFlow. This might involve additional steps such as converting the data to `tf.data.Dataset` objects or applying necessary transformations to align with TensorFlow's data handling mechanisms.\n",
                "- More information on this integration process can be found in [HuggingFace's documentation](https://huggingface.co/docs/datasets/use_with_tensorflow).\n",
                "\n",
                "By following these steps, you can leverage the robust data preprocessing and management capabilities of the BirdSet datamodule within a TensorFlow environment, facilitating an efficient and streamlined model training and evaluation process."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "456bf946-c60a-451b-b290-5249ac68e36b",
            "metadata": {},
            "source": [
                "### Mapping of Labels to eBird Codes\n",
                "\n",
                "The eBird codes in the BirdSet datasets are in integer format. However, we can map these numeric labels to their corresponding eBird codes as defined in the `dataset_info.json` file (it is created during data preprocessing in the folder where the preprocessed data is stored; i.e. in `data_dir` of the `DatasetConfig`). The `get_label_to_category_mapping_from_metadata` function does this by parsing the JSON file and creating a dictionary that maps each numeric label to its corresponding eBird code in string format."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "id": "9ebe88e2-a74c-4dd5-94ab-9193418f764b",
            "metadata": {},
            "outputs": [],
            "source": [
                "from typing import Dict\n",
                "\n",
                "def get_label_to_category_mapping_from_metadata(\n",
                "    file_path: str, task: str\n",
                ") -> Dict[int, str]:\n",
                "    \"\"\"\n",
                "    Reads a JSON file and extracts the mapping of labels to eBird codes.\n",
                "\n",
                "    The function expects the JSON structure to be in a specific format, where the mapping\n",
                "    is a list of names located under the keys 'features' -> 'labels' -> 'names'.\n",
                "    The index in the list corresponds to the label, and the value at that index is the eBird code.\n",
                "\n",
                "    Args:\n",
                "    - file_path (str): The path to the JSON file containing the label to eBird code mapping.\n",
                "    - task (str): The type of task for which to get the mapping. Expected values are \"multiclass\" or \"multilabel\".\n",
                "\n",
                "    Returns:\n",
                "    - Dict[int, str]: A dictionary where each key is a label (integer) and the corresponding value is the eBird code.\n",
                "\n",
                "    Raises:\n",
                "    - FileNotFoundError: If the file at `file_path` does not exist.\n",
                "    - json.JSONDecodeError: If the file is not a valid JSON.\n",
                "    - KeyError: If the expected keys ('features', 'labels', 'names') are not found in the JSON structure.\n",
                "    \"\"\"\n",
                "\n",
                "    # Open the file and read the JSON data\n",
                "    with open(file_path, \"r\") as file:\n",
                "        dataset_info = json.load(file)\n",
                "\n",
                "    # Extract the list of eBird codes from the loaded JSON structure.\n",
                "    # Note: This assumes a specific structure of the JSON data.\n",
                "    # If the structure is different, this line will raise a KeyError.\n",
                "    if task == \"multiclass\":\n",
                "        ebird_codes_list = dataset_info[\"features\"][\"labels\"][\"names\"]\n",
                "    elif task == \"multilabel\":\n",
                "        ebird_codes_list = dataset_info[\"features\"][\"labels\"][\"feature\"][\"names\"]\n",
                "    else:\n",
                "        # If the task is not recognized (not multiclass or multilabel), raise an error.\n",
                "        raise NotImplementedError(\n",
                "            f\"Only the multiclass and multilabel tasks are implemented, not task {task}.\"\n",
                "        )\n",
                "\n",
                "    # Create a dictionary mapping each label (index) to the corresponding eBird code.\n",
                "    mapping = {label: ebird_code for label, ebird_code in enumerate(ebird_codes_list)}\n",
                "\n",
                "    return mapping"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "src-xS3fZVNL-py3.10",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
